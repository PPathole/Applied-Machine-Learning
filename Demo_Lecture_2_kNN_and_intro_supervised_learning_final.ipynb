{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNUKczYUJk5-"
   },
   "source": [
    "# <font color = 'pickle'>**Classification of Machine learning algorithms** </font>\n",
    "Machine learning systems can be classified broadly into four categories  based on the amount and type of supervision they get during training and they are :\n",
    "1. Supervised learning\n",
    "\n",
    "2. Unsupervised learning\n",
    "\n",
    "3. Semi-supervised learning\n",
    "\n",
    "4. Reinforcement learning\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1AGf0YbdrsI6DiEpB3HL-jEj65s7X8ElC\" width =500 >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yD4IhDEKMV_9"
   },
   "source": [
    "# <font color = 'pickle'>**Supervised learning**\n",
    "* In supervised learning, models are trained using labelled dataset, where the model learns about relationship between outcomes and inputs. Once the training process is completed, the model can be used to predict the unknown outcomes for new data.\n",
    "* In real life world supervised learning is used for image classification, Risk Assessment, Fraud Detection, spam filtering, customer churn, etc.\n",
    "\n",
    "We can explain about the supervised learning clearly as follows :\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1b70BKFOppKvgNDZ_PznfBfuDs3SyB5uE\" width =600 >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oWN71xGXcxX"
   },
   "source": [
    "## <font color = 'pickle'>**Types of the supervised learning**\n",
    "\n",
    "Supervised learning again can be classified into two categories they are\n",
    "* **Classification** -\n",
    "In classification problem, the output variable is a categorical or nominal, such as Black or White or disease and no disease.\n",
    "\n",
    "* **Regression** -  In regression problem, the output variable is a numerical or continuous such as price, weight, age etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xv62eHu8YFib"
   },
   "source": [
    "## <font color = 'pickle'>**Some of the supervised learning algorithms**</font>\n",
    "Following are the most important supervised learning algorithms :\n",
    "1. k- nearest neighbors\n",
    "2. Linear regression\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machines(SVMs)\n",
    "5. Decision Trees and Random Forests\n",
    "6. Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrRtADeMGafm"
   },
   "source": [
    "# <font color = 'pickle'>**k-nearest neighbor (kNN)**\n",
    " We can compare the kNN with the famous saying as -\n",
    "**“BIRDS OF FEATHER FLOCK TOGETHER”**. Since this algorithm assumes that\n",
    "similar things exist in close proximity. In other words, similar things are near to each other.\n",
    "*  K- Nearest Neighbors is one of the easiest classification algorithms of supervised learning.\n",
    "\n",
    "* It has applications in pattern recognition, data mining, and intrusion detection\n",
    "* It is widely used in real-life scenarios since it is **non-parametric**. (Non-parametric data does not make any underlying assumptions about the distribution of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoR90DOTJRNv"
   },
   "source": [
    "## <font color = 'pickle'> **How kNN works**</font>\n",
    "\n",
    "We can check the following steps for understanding the process of kNN and how to implement it.\n",
    "1. split the dataset into the training and test data\n",
    "2. choose the value of k (number of nearest neighbours)\n",
    "4. for each point in the test data:\n",
    "  * find the distance (e.g. Euclidean distance) to all the training data points.\n",
    "  * store the distances in a list and sort it.\n",
    "  * choose k data points which are nearest to the focal test data point\n",
    "   (based on the euclidean distance).\n",
    "  * assign the class to the focal test data point based on the majority of classes present in the k closest points in the training data.\n",
    "4. End\n",
    "\n",
    "Note: For regression problem we predict the outcome for the focal test data point based on the average of outcome of k closest points in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "703vREdXcejr"
   },
   "source": [
    "## <font color = 'pickle'>**Importing libraries**</font>\n",
    "First let us import the required libraries for executing our model such as :-\n",
    "1. matplotlib - for visualizing the data\n",
    "2. scikit learn - to build the classification dataset\n",
    "3.  Numpy - for array manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ELhbpFgDcdP6"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na4sQLcpdlk1"
   },
   "source": [
    "## <font color = 'pickle'>**Generating classification dataset** </font>\n",
    "* Classification is the problem of assigning labels to observations.\n",
    "\n",
    "* The **scikit-learn** Python library provides many functions for generating samples from configurable test problems for regression and classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3Zgvtktg1z6"
   },
   "source": [
    "### <font color = 'pickle'>**make_blob classification** </font>\n",
    "* The **make_blobs()** function in scikit learn can be used to generate blobs of points with a Gaussian distribution.\n",
    "\n",
    "\n",
    "**Syntax** :\n",
    "\n",
    "\n",
    "```\n",
    "sklearn.datasets.make_blobs(n_samples, n_features, centers=None, cluster_std, center_box , shuffle=True, return_centers=False)\n",
    "```\n",
    "Here,\n",
    "\n",
    "n_samples = total number of the points equally divided among the clusters\n",
    "\n",
    "n_features = Number of features for each sample\n",
    "\n",
    "cluster_std = standard deviation of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvvoEfJifIse"
   },
   "source": [
    "With the help of above libraries. Let's generate a data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1662323550600,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "ZJJSAq_1i9pP",
    "outputId": "095f4754-250d-44b5-80da-09fe8919f368"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1adc067deb8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAFZCAYAAAAozrxVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDFUlEQVR4nO3dd3hc5Znw/+9zZtQ86sWSZctVstwtGxt3g01dIIAhBAIsBAIkQPZdEt60fd/fZjd7ZRMSEsiyJGQDJOR6IRAIOLtUA65Y7lWyjeUi2XJRtTUz6tKc5/eHLKE2o5E0VXN/fOmydM4z59yypXue81SltUYIIYRvGMEOQAghRhJJqkII4UOSVIUQwockqQohhA9JUhVCCB+SpCqEED4kSVUIIXzIGuwAPFFKKSAbcAY7FiGEABKAc9rDAP+QTqp0JNQzwQ5CCCG6GQecdXcy1JOqE6C8vJzExMRgxyKEiGAOh4OcnBwY4Mk51JMqAImJiZJUhRBhQTqqhBDChySpCiGED0lSFUIIH5KkKoQQPiRJVQghfEiSqhBC+FBYDKkaqS5evMimTZvYv38/7e3tTJo0iSuvvJIpU6YEOzQhxBBJUg2SkpISnnvuOdrb2zFNE4Da2lp27tzJl770JW666aYgRyiEGAp5/A+CxsZGnn/+edra2roSKtD1+f/8z/9w8ODBYIUnhBgGSapBsH37dpqbm3G3JoNhGHz88ccBjkoI4QuSVIOgpKSEjgW4+meaJsePH3ebdIUQoUuSahBIshRi5JKkGgR5eXkeE6thGOTm5nqszQohQpNfk6pSyqKU+jelVKlSqkkpdUIp9f+pCM8WS5YsISYmxm3SNE2Tq6++OsBRCSF8wd811e8DjwLfAqZf+vp7wD/4+b4hzWaz8fjjj2O1WjGML/4LOj+/6aabmDt3brDCE0IMg/Jn+55S6l2gUmv99W7H/go0aa3v7ad8DBDT7VACcMZut4/I9VQvXLjQY/D/xIkTWbVqFbm5ucEOTQjRi8PhICkpCSBJa+1wV87fSfWfgEeAa7XWJUqpucA64Dta61f7Kf8vwI96Hx+pSVUIET68Tar+nlH1MyAR+Fwp5QIswP/pL6Fe8lPgV92+TkD2qBJChBF/J9WvAPcAdwOHgALgWaXUOa31K70La61bgJbOryO8P0sIEYb8nVR/AfxMa/36pa+LlFITgB8CfZKqEEKEO3/3/o8CzF7HXAG4rxBCBIW/a6r/A/wfpdRpOh7/5wHfAV72832FECIo/J1U/wH4N+A3wGjgHPA74Md+vq8QQgSFX5Oq1toJPHHpQwghRjxp2xRCCB+SpCqEED4kSVUIIXxIkqoQQviQJFUhhPAhSapCCOFDklSFEMKH/D34XwgxQrhcLo4cOdK1BN60adOwWCzBDivkSFIVEc80TYqKijh69Chaa3JzcykoKJCE0c3OnTv5y1/+gtPp7DqWmJjIV77yFRYuXBjEyEKPJFUR0SoqKnjuueeoqanpSqLr168nOTmZxx9/nPHjxwc5wuDbuXMnL730Up/jDoeDF198EaUUCxYsCEJkoUnaVEXEamxs5Je//CUXLlwAOh5vXS4X0JEwnnnmGex2ezBDDDqXy8Wbb77pscybb76JafZejC5ySVIVEauwsBCn09lvQjBNk6amJjZv3hyEyEJHSUkJDofbnUMAqKur4/jx4wGKKPRJUhURa/fu3Xjao01rza5duwIYUegZKKF2ivQafXeSVEXEam5u9kmZkSw5OdmrcikpKf4NJIxIUhURa+zYsRiG+18BwzDIzs4OYEShJy8vb8CEmZaWxuTJkwMUUeiTpCoi1sqVKz12sJimyZVXXhm4gEKQYRjcdddd/Z5TSqGU4qtf/arHN6dII/8SImJNnTqVK664wu35yy+/nLlz5wYwotBUUFDAY489Rnp6eo/j6enpPP7448yePTtIkYUm5amhPtiUUomA3W63k5iYGOxwxAiktWbLli2sW7eO6upqAFJTU7nmmmu48sorpQbWjdaakydPYrfbSU5OZtKkSRG1jXznTDIgSWvttgdPkqoQdCQMh8OB1prExERJpqIPb5OqzKgSgo72wUu/MEIMi7wdCyGED0lNVYgIcv78+a7H2KysrGCHMyJJUhUiAhw9epQ333yT8vLyrmMTJkzgjjvuIC8vL4iRjTzy+C/ECHfkyBGeffZZzpw50+P46dOn+dWvfsXRo0eDFNnIJElViBFMa82rr76K1rrPOgedxzrPC9+QpCrECHbixAmqq6vdJk2tNZWVlZSVlQU2sBFMkqoQI1htba1X5WpqavwcSeSQpCrECGaz2bwqFx8f7+dIIockVSFGsGnTpg2YWBMTE5k6dWqAIhr5JKkKMYJZrVZuu+02j2XWrFkjmxz6kIxTFWKEW758Oe3t7bz99tu0tLSglEJrTWxsLLfffjtLly4NdogjiiyoIkSEaGlp4eDBg9jtdpKSkpg7dy7R0dHBDitsyIIqQogeYmJiWLhwYbDDGPGkTVUIIXxIkqoQQviQJFUhhPAhSapCCOFDklSFEMKHJKkKIYQPSVIVQggfkqQqhBA+JElVCCF8yO9JVSk1Vin1/5RStUqpJqVUkVJqgb/vK4QQweDXaapKqRRgK7AB+DugGsgDLvrzvkIIESz+nvv/faBca/1At2Ol7gorpWKAmG6HEvwVWCSor69n69atHDx4kPb2diZNmsQVV1zBmDFjgh2aECOWX1epUkodBj4CxgFXAGeB32itf++m/L8AP+p9XFapGrzS0lJ+/etf09zc3LU/kWEYmKbJXXfdxapVq4IcoRDhxdtVqvzdpjoZeBQ4BlwH/Bb4D6XU/W7K/xRI6vYxzs/xjUhNTU38x3/8R4+ECmCaJgCvv/66bEsshJ/4+/HfAHZrrf/p0tf7lFKzgG8Cr/QurLVuAVo6v1ZK+Tm8kWn79u00Nja6PW8YBh9//DH5+fkBjEqIyODvmup54HCvY0eA8X6+b0Q7cuSIxzck0zQ5fLj3f4sQwhf8nVS3Ar2rQ1OBU36+b0TTWrvd5717GSGE7/k7qT4DLFZK/ZNSKlcpdTfwCPC8P26mteb8+fOcOHGCuro6f9wiLEyePNljTVUpxeTJkwMYkRCRw69tqlrrXUqpNXR0QP0zHcOpntBav+rrex04cIC1a9dy7ty5rmOzZs3ijjvuICsry9e3C2nLli3j3Xffpb29vd/zWmuuuuqqAEclRGQYERv/7dixg5dffrlrl8hOhmEQExPDD37wg4hLrAcOHOCFF14Avuj17xxSddVVV3HHHXdIR6AQg+DtkKqwT6qtra1897vfpbm5ud/zhmEwa9YsHn/8cT9GGprOnTvHhg0b2L9/f9fg/1WrVjFr1ixJqEIMUsTsprpv3z63CRU6amlFRUVd2/JGkuzsbO655x7uueeeYIciRMQI+1WqampqMAzP34bWmgsXLgQoIiFEJAv7pGqz2bwaHmSz2QIQjRAi0oV9Up03b96Aw4dycnIYPXp0AKMSQkSqsE+qSUlJAw4PuvXWWwMTjBAi4oV9RxXAbbfdhlKKTz75BNM0u4YOjRo1invvvZdZs2YFO0QhRIQI+yFV3TkcDvbv309jYyMZGRnMmTOHqKgo/wcqhBjxImZIVXeJiYmsXLky2GEIISLYiEqqQvTHbrdz6tQpDMNgypQpxMXFBTskMYJJUhUjTnV1NSdPnqSlpYWioiKKioq6ht1ZrVZWrlzJbbfdJk1Dwi8kqQqvaa1xOBxorUlMTBxw0kWgORwOXnnlFYqLi92WaW9vZ8OGDVRVVfH444+H3Pcgwp8kVTEgrTWfffYZ69ato6qqCoCUlBSuvvpqVq9eHRKJqbm5maeffprq6uoBy2qtKS4u5siRI8ycOROAyspKCgsLqampwWazsWjRogGXUBSiP5JUhUdaa9544w02bNjQ4/jFixd58803KS0t5etf/3rQE+tnn31GVVWV14tvG4bB1q1bmTFjBu+88w4fffQRhmGgtUYpxaZNm5g5cybf/OY3iY6O9nP0YiQJfhVDhLTjx4/3Sajd7d69m/379wcuIDcKCwsHtZuBaZrU1tayYcMGPvroo65jWuuupRIPHz7Mn/70J6+uV1dXR1FREYcPH/a4wI8Y+aSmKjzavHlz12SK/hiGwaZNm5g/f36AI+vJbrcPqrxhGCQmJvLBBx+4LaO1ZteuXaxZs4a0tLR+yzidTl577TX27dvXldSjo6O58sorufXWW7FYLIOKS4Q/qakKj86ePes2oUJH7e7s2bMBjKh/ycnJgypvmiYXL17E4XA7hhvoWDuiqKio33NNTU384he/YP/+/T1qya2trXz88ce8+OKLshdYBJKkKjyKjY31SRl/W758+aBfc+bMGa/KtbW19Xt806ZNVFVV9fumo7Vm7969HDt2bNBxifAmSVV4tGDBAo/nlVIsXLgwQNG4t3TpUsaOHTuoDjNvapFaa8aNG9fvuS1btni8RmdnmIgsklSFR0uWLCEpKanfZGUYBrGxsVxxxRUer1HdVM2BmgMU1RbhbHX6Jc6YmBiefPJJ5s+f32MYlMViYf78+dxzzz1Mnz59UElXKUV6ejr5+b13We8w0I69pmnK4ugRSDqqhEdxcXE8+eSTPPfcc1RXV2MYBkopXC4XCQkJfOtb33LbnmlvsfPOyXcoc5Z1HVMo5qbP5YYJNxBt8e1QJZvNxsMPP8wdd9xBWVkZSimmTJlCfHw8AO+++67H9uHuDMPAarXy8MMPu03E8fHxHhNrZ2eYiCySVMWAMjMz+fGPf0xxcTGff/45Wmtyc3MpKChw27vd2NbIS0de6lMz1WgO1BzA0erg3vx7MdTANcfKxkqKaotobG8kOSaZgvQCEqPdJ6vk5GQKCgr6HHfXNtqb1Wrl8ssv5/rrryczM9NtuWXLlvH++++7bQIwTZMlS5Z4dU8xckhSFV4xDIM5c+YwZ84cr8rvrNqJs9WJpm/C0WhOOk5ywn6CvOQ8t9doN9t55+Q7HLpwCAMDVEcb54YzG1g1bhUrswe3IllOTg7Hjh3zODxs6dKl3HPPPV41E6xatYrPPvsMp9PZ55pKKaZOncqMGTMGFWOkM7VJSV0Ju6p2UdNUQ5w1jtlps5mfMZ84a3gshCNtqsIv9lbv7TehdlIoDtQc8HiN98re4/CFwwCYmJjaRF/6s/7MevZW7x1UTFdeeeWAw8OuvPJKr9tdExIS+N73vsekSZN6HFdKcfnll8vaAoPk0i7eOv4Wrx97nZP2k9hb7VQ0VvBJ+Sc8X/Q8tc21wQ7RK1JTFX7R2Nbo8bxG42xz32llb7Wz89BO6g/V03KuBYCYMTHYZtmIzuxoi914diMF6QVeNSFAx35mS5cupbCwEKVU12N75+dr1qwhJyfHq2t1Sk9P53vf+x5nz56lrKwMi8XCtGnTBj1uVkDh+UIOX+x4E+3+hqzRNLY18ueSP/P47MdDfj0GSarCL+Kj46lrqXN7XqFIik5ye37th2upea8GFHT+fjWfaqa5rJnExYnYZtpwtDqobKxkjG2MVzEppbjvvvvIzc3l008/7Zq0MHnyZK677jrmzp3r7bfXx9ixYxk7duyQXw/gcrloaGggNjY24tYbcGkX2yu2uz1vYlLTXEOpo5TJSZMDGNngSVIVfnFZxmWsP7PebROARlOQUdDvufLycgrfK+ws2P1FADi2O4jOjCYqPYpWs3VQcSmlWLZsGcuWLaOtrQ2lFFZrcH8NGhoa+OCDD9iyZQvNzc0opZg9ezY33ngjEydODGpsgXKh+QIN7Q0eyxgYnHKeCvmkKg0+wi8Wjl5ISkxKRwdTLwpFfnI+kxIm9fNK2LBhA8rw8IinoOFwAwpFWmz/c/K9ERUV5feEqrWmzWxzO0Kgvr6en/3sZ3z66addC7F0Lk341FNPcejQIb/GFyoUof1IPxhSUxV+EWuN5cEZD/Ju6bt8Xvd513GrsrJg9AKuzrnabdvYsWPH0KaH2U4aWitamZ4ynfioeF+H7hOOVgeF5wvZV7OPFlcL0UY08zLmsWzMsh7DwdauXUtNTU2fDjTTNFFK8dJLL/HUU0+N+F0KUmJTsFltHmurJiYTEicEMKqhkaQq/CY+Kp67pt6FvcXO+cbzGMpgfPx4Yq2e1wrwpsfcMAyun3C9r0L1qQvNF3jp8Es0tjd2NX+0mq3srNxJUW0RD814iNTYVJqbm9m2bZvbEQlaaxoaGti/f39ITAX2J4uysDhrMZ+e+bTf8wpFemy626ebUCKP/8LvkmKSmJYyjanJUwdMqACzZ8/2mFiVUiyet9jjBIBg+lvp33ok1E4aTVN7E2tPrgWgtraW9vZ2j9eyWCycP3/eX6GGlKVjljIjtWNcb+/mgM436FDv+QepqYoQdMUVV7B+/Xq35w3D4JrV1wQwIu9VN1VzynnK7XmN5nT9aaqbqr3q4ddaR8xIAIuy8OUpX+ZY2jF2Ve2itrmWWEsss9NmMy9jXtgM/pekKkJORkYG3/jGN/jd737XtRo/dNRQDcPgkUce8Th9NJgqGyu9KlfRWMGs9FlkZWVRWVnpcaprf1NuRypDGeSn5JOf0v8iNuFAkqoISXPnzuUnP/kJW7Zs6VpvYNq0aaxYsYLU1NRgh+eW1fDuV8pqWFFK8aUvfYnf//73/ZZRSlFQUEBWVpYvQxR+JklVhKyUlBRuvvlmbr755mCH4rWJiROxKivt2n1bqVVZuzpcFixYgMPh4M033+zadBA6aqgzZ87kgQceCEjcwnckqQrhQ7GWWBZlLWLrefeLU1+eeXmPDrvVq1dz2WWXsW3bNqqrq4mLi2PBggURM/B/pJGkKoSPrR63mvrWeg7UHsDAQKNRKExM5qTN4aqcq/q8JikpieuvD80hYmJwVChvTKaUSgTsdrtdFvsVYedcwzkO1BzA2eYkISqBuelzybZlBzssMUQOh4OkpCSAJK212x0jpaYqhJ9k27IliUYgGfwvhBA+JDVVIcLIhQsX2Lp1K1VVVV0dWnl5eWEx0yhSBCypKqV+APwU+LXW+olA3VeIkeLDDz9k7dq1XYtqK6XYtGkTU6dO5bHHHiMuLjxmHI10AUmqSqmFwDeAg4G4nxDuVFZWsnnzZk6dOkVUVBRz5sxh8eLFIZ+QduzYwTvvvAPQNfuq8+/jx4/z0ksv8a1vfSto8Ykv+D2pKqXigVeBh4H/6+/7jQQ1NTUcPXoUgClTpsiMGh/ZsGEDr7/+OoZhdK0MdfjwYd577z2+/e1vD3vlfn/RWvPee++5PW+aJkVFRZw7d47sbN92jLW3t7N37162bduG3W4nLS2N5cuXD7joTSQLRE31eeA9rfUnSimPSVUpFQPEdDuU4NfIQkxDQwOvvPIKBw703BBv+vTpPPDAA53DOcQQHDlyhNdffx2gz1J7DQ0NPPvss/zkJz8JycVLqqurqaz0vKaAYRgcOHDAp0m1oaGBX//615w6daqryeH8+fMcPHiQmTNn8uijj4bVOq+mNjl84TC7q3ZT01xDrCWWOelzuCzjMmxRNp/dx69vNUqpu4D5wA+9fMkPAXu3jzN+Ci3ktLW18cwzz1BUVNTn3NGjR3n66ae7VoYXg7du3Tq3NSvTNHE4HOzZsyfAUXmnra1twDJKKa/KDcYrr7xCeXk58EVTQ/ca/ttvv+3T+/mTy3Tx+rHXeevEW5xynqK+rZ6a5ho2nNnAb4p+Q01Tjc/u5bekqpTKAX4N3KO19jYb/BRI6vYxzk/hhZw9e/ZQXl7e74LFpmlSVVXF1q3upz4K90zT5MiRIx63p1ZKhezWJWlpaQPWCF0ul0+bL2pqajhw4IDHBbS3bNlCU1OTz+7pT1vOb6GkrgToZ6fW9kb+fOzPblcKGyx/1lQvA0YDe5VS7UqpduAK4H9d+trS+wVa6xattaPzA3C/h/EIs23btgGHxUhSHTpvfmFcLlcAIhm82NhYli5d6ramrZQiISFhWLvB9tbZpu9JW1sbpaWlPrunv7Sb7eyo2OH2vEZT21zLScdJn9zPn22qnwKzex37A/A58JTWOjR/goPEbrcP+IvvcLidGTeiNDY2sn37dk6ePIlhGEyfPp0FCxYMuf3OMAxycnI4c+aMx3/jSZNCd6uOW265hZKSEioqKnp8D4ZhYBgGDz30kE83MfS21hbK09w7XWi5QJPLc43awOC08zRTkqYM+35+S6paaydQ3P2YUqoBqNVaF/f/qsiVlpbW5xemO6UUaWlD3zk0XBw6dIjf/e53tLS0oJRCKcWOHTt4++23eeKJJ4b8iHvVVVfxxz/+0e15q9XK0qVLhxi1/9lsNr7//e+zbt06Nm/eTH19PYZhMH/+fK6//npycnJ8er/JkwfeBtowDCZMCP2N+LzdqdVXEyhkRlWIWLZsGcXF7t9rtNasWLEigBEFXkVFBb/5zW+6HsO11l1vMvX19TzzzDP827/925DGlC5evJiSkhIKCwu7erLhi00GH374YeLjQ3Nn1k5xcXHccsst3HzzzbS0tBAVFYXF0qcVzSeys7PJz8/n2LFj/barGobBokWLQv7fDCA1NtWrnVonJkz0yf0CmlS11lcG8n7hpKCggGnTpnH06NE+tdXOx9dFixYFKbrB63yEP3XqFI2NjdhsNsaNG8fs2bPdboWyfv36HtundGeaJk6nk23btrF69epBx6OU4r777mPWrFmsX7+e8vJyLBYL8+bN46qrrgrZMar9UUoRGzvwBorD9eCDD/KLX/yC2traHlvaaK0ZN24cd955p99j8AWLsrBkzBI+Kf+k3/MGBhlxGUxI8E2tW5b+CyGtra389a9/5bPPPuvaZbOzRnDnnXeG/KyfTvv37+fFF190O8Rn7ty5PPDAA32+n+9+97sDthvn5+fzne98x2exhqqqpir2VO2huqmaGEsMM1JnMD1lutfbtfhKU1MTn332GVu3bsXpdJKamsqKFStYvHhxSI7pdcfUJmtPruVg7UEMDEy+qH0nRSfxwPQHSI5J9ngNb5f+k6QaghobGyktLUVrzcSJE8PiEatTWVkZTz31lMfhS4ZhMHnyZJ588skePdpPPPHEgEN0Jk2axA9+8AOfxRuKNp7dyMazG7t++RUKjSYtNo37pt1HUrRMAhkKrTUn7CfYXb2b2qZaYq0dO7XOTZ9LjCVmwNfLeqphbNSoUcycOTPYYQzJunXrBixjmibHjx/nyJEjPb7PnJwcjh075razLlw6RobjYM1BNp7dCNBVm+ocV3mx+SKvHX2Nb876pqxKNQRKKXKTc8lNzvXrfSSpCp/RWrN//36PtdROhmFQWFjIxYsXcTgcpKSksGzZMkpKSty+xjRNVq5c6cuQQ4rWms/Of+b2vIlJZVMlpc5SJicO3DsvgkOSqvAZrbXXA+hN02T37t3s3r27a4GTqKgopkyZwokTJ/r00Jumye233x5WHUqD1dDeQFVTlccyhjI4XndckmoIk6QqfMYwDDIzMwdc/KO3zpptW1sbJ06cYPny5ZSVlXHmTMfSD1OmTOG6665j9uzec0l8x9HqoK6ljjhrHOmx6UF5vHaZ3r0huWTeTEiTpCp8atWqVV2rQQ1VcXExP/3pTzFNE6WU38ZiAlQ3VfPh6Q85YT/RdWx03GiuzrmaqclT/Xbf/sRHxw88nlKbsu9ViJMFEYVPrVy5ctidbHV1dZw8eRKr1er3hPri4Rc5ae8557uqqYrXSl6juDawE/8sysLlmZe7nQGkUMRZ45iROiOgcYnBkaQqfMpisfD444/z5S9/meTk5D7nY2IGHroCHWt5+ttHpz+i1dXaY9Wi7t4te5c207fL6Q1k2ZhlTErsuwaBgYHFsHBn7p1EGeGzhmkkksd/4XMWi4VrrrmGq6++mubmZlpaWqitrcVisVBfX89zzz034DUyMjL8GqOj1cFx+3GPZZpdzRy9eJRZabP8Gkt3VsPK3VPvZl/NPnZV7qK2uZYoI4pZabNYnLmY9Lj0gMUihkaSqvAbpRRxcXHExcV11VpN0yQ1NZWLFy/2Ox5VKcWECRN8vi1Ib3UtdQOWMTC42HLRr3H0x2pYWTh6IQtHLwz4vcXwyeO/CCjDMLj33nu7VqDqTimF1Wrlq1/9qt/jiLMOPOXXxPSqnBDdSVIVATdz5ky+/e1vM3HixB7H8/Pz+d73vtfnuD+kx6YzOm60xzKGMpieMt3vsYiRReb+i6Cqrq7G6XSSnJxMampqQO9dUlfCayWvuT2/fMxyrs65OoARiVDm7dx/qamKoGgz2zhWd4xKo5K4zLiAJ1SAqclT+fKULxNr6VhGz7j062Aog+VjlrN63OCXGBRCOqpEQGmt2VaxjU3nNtHiauk6njUqi5sn3Rzwge2z0maRn5LP0YtHudhykThrHNNTpvt0y2IRWeTxXwRU57J2vSkUVsPKQzMeInNU/4tYCxFM8vgvQo6z1cnms5v7PafRtJvtrD+zPsBRCeFb8vgvAqb4QrHb2UvQkVhL6kpobG9klHVUACMLvlZXK9VN1QCMHjVaZk2FMUmqwie01px0nGRX1S4qGyuJscQwM3Um8zPmd7VPOludPZb06/c6aBraGiImqbaZbWw4s4HdVbtpNVsBiLXEsihzESuzV1LvrOfIkSO4XC7Gjx/v811The9JUhXDprXm3bJ32VO9p2vrD4DKxkoKKwr52rSvkTkqk/ioeK/2ibdZI6OTyGW6eO3oa5Q5y3rU4JtdzWw8vZGNb2+k6khVj0W/J02axNe//nW/T+MVQydtqmLY9lTvYU/1HoAeyUGjaW5v5tWSV3GZLmaneV4PVaGYmjyVUVGRUUstvlBMqbO0T5OI1pqLn1yk4nBFn10UTp06xc9//nPsdvuA13dpFyftJymqLeK087RXb2hi+KSmKoZFa03h+UL359E4Wh3sqtrFuPhxLMpaxPaK7X3KKRQWwxJRY0N3V+3uUbPv1Hq+lZazLf2+xjRN6uvr+fTTT7ntttvcXvtAzQHWnV7XY23WlJgUbpx4I7lJ/t2jKdS0m+2U1JVQ3VRNtCWaaSnTSIlJ8dv9JKmKYWlob+BCy4UBy314+sOuz0fHjaaupa6rDREgIy6DWybdQtaoLL/EGYoutlzst+Ou6XgTKHDXp2eaJlu3bnWbVPdV7+NvpX/r936vHn2Ve/PvZUrSlOGEHjaO24/z9om3aWxvxMBAo/no9EfMSZvDlyZ9yS8dgpJURcDVNNUQY4nh5kk3Y1VW0mLTyLZlR9wOoXGWOOrb6vscdzW63CbUTu7Wm20z2/jo9EduX9eZVB6d9eiI//c+U3+G10pew9QdTSidu9MCFNUW0W6285W8r/j8vtKmKobFZrUN+lHKxKTF1UKpo5Q56XMYGz825H/BtdacPHmSdevW8fHHH3P69OlhX3Nuxtx+V/m3xFtws/h/l0uD0Ps4XnecZlezx9dWNVVR2TS4fcTC0aazm9y2I2s0hy8eprLR9/8OUlMVw6KUYumYpbxX9t6gXmdicujCIW6ccCOx1lg/RecbNTU1/O53v+P06dNdyV9rzZQpU3jkkUf63eHAG5dlXMaOih00tDX0qEWNyhtF09Emt69TSrFixYp+zznbnF7d29nqHNFNLc2uZo7Zj3ksY2BQXFvs8xl8UlMVw3ZZxmXMS58H4HZ/pf6Y2vQ6CQRLQ0MDTz/9dNfOrlrrrtpPaWkpv/zlL2lp6b9TaSBx1jgenPEgo0d1LEGoLv2JGh1Fan7/C8wYhkFaWhqrVq3q93xCVIJX906I9q5cuOq+roRbigFr9UMhNVUxbIYyuHnSzcxIndE1+L/dbPe4K2inzhWiQlG72c6fP/gzFy/2v/q/aZpUVVWxY8cOVq5cOaR7pMSk8I2Z3+BM/RlO13c0KUxKnETmgkz++7//m/Xr19Pa2tGhp5Rizpw53H333dhs/Y/lzU3OJdYS6zFZjI4bTWbcyF5fwWa1EWVEedxjTGvtl1EAklSFTyilyEvOIy85D+joaf71gV+7L48iJz4nZGtM7WY7r5W8xr7d+zyWU0oNK6l2XiMnIYechJ6zpdasWcMNN9zAiRMnaG9vJycnh5QUz0kgyoji2vHX8t+l/93/vVBcN/66kG/DHi6rYaUgvYDdVbvdTo1WSjEnfY7v7+3zKwpBRw1sfsZ89lbvdVtm1bj+H2FDwfbK7ZQ6SjFbTI/ltNbU1/ftwfeVmJgYZswY3JbU8zPmY2DwcfnHfcepTrgxYoZTXTH2Co7WHaW+tb5Hm3Wna3OuJT4q3uf3laQq/ObGCTdiKIM9VR2zrRSqY98nSxy3TL6l362YQ4HWmp0VO9FoLAkWzCbT7RAnwzAYPdrztizBUJBRwOy02ZQ5y2hoayApJomc+BwMFTndKPFR8Tw842E+Lv+Y4gvFXUOr0mLTuHLslQPO8BsqSarCbyyGhZsm3sTK7JUcuXiEFlcLabFp5CfnYzVC90ev2dWMo61juUzbNBt1lXVuy5qm6bYnPtgshiXkaqXnzp3jk08+Yd++fbS1tTFu3DhWrVrFwoULMQzfJ/yE6ARum3Ib10+4novNF4m2RJMem+7X5o/Q/ckWI0ZidCKLMhcFOwyvWZSl6/PYybFEH4um9Vxrv2ULCgqYNWuW32IxtcnhC4fZWbmTisYKrIaV6SnTWZy1mIy48FpUpaioiN/+9rdorbvWNCgrK+Pll1+mqKiIBx980C+JFWCUdRSj4gOzpkTkPAsI4aVoSzTj48d3DHAyFKnXpGKbbUNFfVG7UdGKxVct5pFHHvFbIjC1ydqTa3nrxFuU15fTarbS2N7Ivup9vFD8Asftx/1yX39oamriv/7rv3C5XD0WiekcnrZr1y62bNkSrPB8SpKqEP1Ykb2iq9dYWRWJlyeSeXcmaTenkX5zOjMfmMn9d9yPxWIZ4EpDt7d6LwdrDwI9V/8yMXFpF28ce8Mv4yz9Ydu2bV1Dw9xZv35k7PogSVWIfuQl53HDhBu6BuQDGFaD6IxosnKyuG/mfX7v9OlvNa/u2sw2DtYc9GsMvlJWVjZgjb6iomLAxBsOpE1VCDcuz7ycqclT2Ve9j8qmSqKMKKanTCc/OR+L4b8aKnQkzJrmGo9lFIoz9We4PPNyv8biC942kYyE8bOSVIXwIDkmOSjjab2d7hsuQ6RmzpzJtm3b3J5XSpGXl0dUVPjvzRUe/yNCRBirYe3qLHNHo0NuyJQ78+bNIzU11W2NVWvNtddeG+Co/EOSqhAhatmYZe6nWKJIjE5kesr0AEc1NFarlX/8x38kIaFjWnLnY35nkr3jjjuYPds/g/EDTYXyvjVKqUTAbrfbSUxMDHY4QgTc1vNb+bj84z7brsRHxXP/tPvDbqxqS0sLu3bt6jH4f+XKlWRlhf4yhA6Ho3Md2ySttcNdOb8mVaXUD4HbgGlAE1AIfF9rfdTL10tSHeFqampoaGggJSVF/o/dqGqqYnfVbioavhj8Pyd9DjGWmGCHFlFCJal+CLwO7KKjU+zfgVnADK31gOvCSVIduY4cOcLatWspKysDvljW7vbbbyczc2QvSyfCU0gk1T43UyoDqAKu0Fpv9qK8JNURaP/+/bzwwgsAPba7MAyDmJgYfvCDH4TF46CILN4m1UB3VHVurNPv9ptKqRilVGLnBxCai22OMFprWl2tXav4+FN7ezt/+tOfeqyg38k0TVpaWvjLX/7i9ziE8JeAjVNVShnAs8BWrXWxm2I/BH4UqJgiXaurle2V29lZuZP6tnoUimkp01iRvYJsW7Zf7nnw4EG3O4FCR2I9dOgQFy9eHHBBZiFCUSBrqs/T0Z56l4cyP6WjNtv5MS4AcUWkFlcLfzjyBzac2dC1TbJG8/nFz3nx8Iscq/O8adpQVVdXezW7pra21i/3F8LfApJUlVL/CdwErNJan3FXTmvdorV2dH4Aob0rXBjbfG4zFY0VfcZBajSmNnnrxFu0unw/D9tms/VYpciduLg4n99biEDw6+O/6hjh+xywBrhSa13qz/sJ77Sb7R737oGOmuzhC4cpyCjw6b3nzp3Lq6++6jGxZmZmkp3tn+aHYNNac8x+jD1Ve6hpriHOEsfs9NkUpBfIEKkRwt9tqs8DdwO3AE6lVGeXrl1r7X5jc+FXzjbngFv4GsqgorHC5/dOSEjg6quvZt26dW7L3HrrrSNiYY3eTG3y1xN/5dCFQz0G859pOEPh+UK+Nv1rftndUwSWvx//H6WjbXQjcL7bx51+vq/wwKq8eC/V+G3LkzVr1nD11VdjGAZKqa41SWNiYrj//vuZP3++X+4bbFvPb+XQhUMAfZ4SnK1OXi95vc+ICBF+/FpT1VqPvOrGCJAQnUDWqCwqGyvdNgGYmOSn5Pvl/oZhcMcdd3DttdeyZ88eGhoaSE9PZ/78+cTEjMxHYJfpYluF+1WaTEwqmyo5XX+aCQkTAhiZ8DVZ+i9CrcxeyV+O9z8eVKHIic9hnM2/gy+SkpJYvXq1X+8RKmpbamlsb/RYxsCg1FEqSTXMySpVEWpG6gyuH39918r2CoVx6cch25bNXXl3jch2zaCRp/qIITXVCLY4azHTU6ezr3ofNU011NvrMSoNEs8nUm4tZ+rUqZJYfSQ1NpU4SxxNLvf9syYm4xPGBzAq4Q+SVCNcUnQSuTqXdS+vo7a2FovFgtaaD97/gHHjxvHYY4+RlpYW7DDDntWwsihrERvPbuz3vEKRFpvGpIRJgQ1M+Jyspxrh7HY7//Iv/0Jzc3OfsaOGYZCSksKPfvSjEduBFEgu08Ubx9+gpK6kx5AqhcIWZeOB6Q+QFitvYIOltebo0aNs374du91OSkoKS5YsITc316dPWt4uqCI11Qi3ceNGmpqa+h3KY5omtbW17Ny5kxUrVgQhupHFYli4K+8ujlw8wu7K3dQ21xJrjWVO+hzmZ8xnlHVUsEMMO21tbbzwwgsUFxdjGAamaWIYBlu3bmX+/Pk89NBDft1GvD+SVCPczp07PY6NVEpJUvUhQxnMTJ3JzNSZwQ5lRHj99dc5dKhj7G/nk1bn3/v27eOdd97hy1/+ckBjkt7/CNfU5Hlim9Z6wDJCBIPD4aCwsNBtpUBr3fUkFkiSVCNcVlaWx3YnwzAYM2ZMACMSwjtHjx4dcHGetrY2jh8/HqCIOkhSjXBXXHGFx8d/0zTl0V+EJJfL5VW59vZ2P0fSkyTVCLdgwQJmzZrltra6YsUK8vLyAhyV8CeXdnGs7hh7q/dSUldCuxnYpOMrEyZ4N/Ns/PjAjv2VjqoIZ7FYeOyxx/jggw/YsGED9fUdC1anpKRw7bXXsmrVKpkAMIIU1xbzwakPaGj/YveFUdZRXDv+WgrSC4IX2BCMGTOGvLw8Tpw40W8zgGEYzJw5M+DjrGWcqujicrmoqanBMAzS0tK8WqFfhI9DFw7x5vE33Z5fM3kNc9PnBjCi4autreWpp57C4XD0aMZSSpGamsr3v//9zrGlwxaSu6kOliRVIXzD1CbP7n8WR5vbXIDNauM7Bd/BYgR2XOdwORwO1q9fT2FhIU6nk8TERJYvX87q1aux2Ww+vY8M/hdhrb6tnnMN51AoxsWPI84auC1WnK1Oii8UU99WT2JUIrPSZmGL8t0vaKCddp72mFABGtobKHWWkpuUG6CofCMxMZFbb72VW2+9NdihAJJURQhqam/i/VPvc6j2ECYdbWUWZWFe+jyum3AdUUaU3+6ttWb9mfV8dv4zoOMxUmvNR+UfsWrsKpaPWR6Wbczd21A9lmvzrpxwTxrNREhpM9t45fNXKK4t7kqo0NFjvad6D6+VvIapB944cKg2n9vMlvNb0Jf+mNrs+vvTM5+yq2qX3+7tTwlRCV6VS4yWZrbhkqQqQsr+mv397vIKHVuQlDpKOVp31C/3bnG1dNVQ3dl4dmNYDkHKic8ZcP+rxOhEWSDbBySpiiFzuVx8/vnn7Nmzh7KyMp/sr7S3aq/H8wrFvup9w75Pf07YT9Bmtnks09jeyOn60365vz8ppbhhwg0o3Ddd3DDhBgwlKWG4pE1VDMnWrVtZu3YtDscXnR9ZWVncc889TJ06dcjXtbfaPZ7XaOpa6oZ8fU8G2mF2sOVCTV5yHndPvZsPT39IbXNt1/GUmBSuH3+93/YkizSSVMWgbdq0iddee63P8crKSp555hmefPJJcnOH1oMcHxXvcS8nhfK6fXCwvF3LNC0mfNc8zUvOIzcpl3MN53C0OUiISmCsbWxYdr6FKqnri0FpaWnhr3/9a7/ntNZorXnrrbeGfP15GfM8ntdoCjIKhnx9T3Lic0iLTXP7iKxQjLWNZfSo0X65f6AopRgbP5bpKdMZFz9OEqqPSVIVg3LgwAFaWtw//mqtKS0tpbKyckjXn58xn9SY1H4Tm0KRbctmesr0IV17IEopbpl0C4Yy+txfoYgyovjSpC/55d5i5JCkKgbFbrd7NX3VbvfcNupOjCWGB6Y/wOSkyX3OTU+Zzt/n/z1Ww3+tVuMTxvP1GV9nStKUrmMKRX5yPg/NfIisUVl+u7cYGaRNVQxKYmLigGtYAsOab50QncDf5/89tc21lDvLUUoxIWECyTHJQ77mYGTbsrk3/14a2hpoaG8g3hrPqCjZ6kR4R5KqGJS5c+cSHR1Na2trv+eVUowfP57MzMxh3ystNi2oG+HZomxhPTXVV5ytTk45T2Fqk5yEgce7RjpJqmJQYmNjWbNmDW+88Uafc0oplFIB3xNI+EeLq4X3yt6jqLaox2SMvOQ8bpl0C/FR8W5fa2qTdrOdKCMq4jrCZJUqMSSbNm3ib3/7Gw0NX8wVz8jI4J577mH6dP90JInAcWkXrxx5hfL68j6z2wwMUmJTeGTmI8RYem5dfr7hPJ+d/4wjF45gYmKz2liYuZAlWUv6lA03svSf8Lu2tjY+//xzGhoaSEtL8/k+6yJ4Blp7FeC68dexJGtJ19fH7cf5c8mf0Vr3WLdBocgclcnXpn+NWEus32L2N2+TqvT+iyGLiopi9uzZLF68mLy8PEmoI8j+6v0ep7QCPaYLt5ltvHX8LVza1SOhQsfY4srGSjae2eiPUEOOJFUhRB/ONme/i9r0KNPq7Pr8yIUjNLua3ZbVaPZW7x1wbYWRQJKqEKKPxOjEAWuqCdFfTBeuaKwYcDGWVrMVR6vnhbJHAun9F15pbm5m27ZtFBYW4nA4SE1NZfny5Vx++eVERflv0WgRHPPS51FSV+KxzGUZl3V9HmVEMUDFFgCrGvkpZ+R/h2LYHA4HTz/9dI+pp3a7nZMnT7JlyxaeeOIJYmPDtwNC9JWfks/EhImccp7q0wygUKTHpvdYgyE/JZ9N5zZ5vObouNERsQi2PP6LAf3hD3+gurq6x7HOUSNlZWX85S9/CUZYwo8MZXD31LuZlzGvx2O9QjEtZRoPTH+gxxCpbFs2kxImeWwyWJm9MiI6M2VIlfCosrKSf/7nf/ZYxmKx8POf/5z4ePeDwUX4amhr6BivqjVj48e6rW02tTfxasmrnKk/g4HRo4Z7Tc41LB2zNFAh+4Xspip84vjx4wOWcblclJWVMWvWrABEJALNFmVjWsq0AcvFWeP4+vSvU+oo5dCFQ7S4WkiLTWN+xnySYoa+FkS4kaQqfCISHuvEwJRSTE6a3O8qY5FCkqrwyJutUaxWKxMnTvR/MCOQS7sod5bT7GomNTaV0XHhvQC2kKQqBpCRkcGcOXMoLi7ud8k/pRTLli3DZpPVnAZrd9VuNpzZQEP7F+snjLWN5aaJNzHGNiaIkYnhkN5/MaD777+f7Oxs4IvH/M6/p06dKqtSDUHh+ULeLXu3R0IFONdwjpePvExl49B2ThDBJ73/wittbW3s3r2brVu3dg3+X7FiBQUFBVgslmCHF1aa2pt4et/TuLSr3/MKRW5SLvfk3xPgyIQnIdX7r5R6HPgukAUcAP5Ba70zEPcWvhEVFcWSJUtYsmTJwIWFR8UXit0mVOiYJ3/Mfoz6tnqPa5aK0OT3x3+l1J3Ar4B/BebTkVQ/UkpJi7yISM5W54Dz5AHq2+oDEI3wtUC0qX4H+L3W+g9a68PAN4FG4MEA3FuIkGOLsuFNs5vNKp1/4civSVUpFQ1cBnzSeUxrbV76us9zpFIqRimV2PkBJPQuI0S4m5k60+N0ToViUuKkHqtAifDh75pqOmABendlVtLRvtrbDwF7t48zfo1OiCCIj4pnefbyfs8pOvb5umrcVQGOSvhKqA2p+imQ1O1jXHDDEcI/Vo1dxepxqzuWzOsmOSaZ+/LvY1y8/OiHK3/3/tcALqD3fsWZQEXvwlrrFqCl82uZ+hjZtNYcrTvKjsodnK0/i6EMpiZPZXHWYrJt2cEOb1iUUqzMXsmizEWcsJ/omFEVk8qEhAnycx/m/JpUtdatSqk9wFXAWgCllHHp6//0571FeNNa89Hpj9heuR2F6lrxqLi2mKLaIm6bchuz02YHOcrhi7HEMCN1RrDDED4UiMf/XwEPK6XuV0pNB34L2IA/BODeIkx9Xvc52yu3A/RYQs7ERKN55+Q72FvtwQpPCLf8nlS11m8A/xv4MbAfKACu11rLPDzh1o6KHR57yLXW7K3aG8CIhPBOQGZUaa3/E3ncF4NwpuGMx908NZry+vIARiSEd2SVKhGSDC8eoryZlTTStLpaKXOW0Wa2MTpuNBlxGcEOSfQiSVWEpNykXD6/+DkmfZcb7F4mUpjaZPO5zRSeL6TVbO06nhOfwy2TbiE9Lj2I0YnuIu+tXoSFJWOWuE2oCkWsJZaC9ILABhVEH576kI1nN/ZIqABn6s/w4uEXudhyMUiRid4kqYqQ1FkDU5f+dBdjieHe/HuJtfpuW2xTmx5XjgqmmqYadlb1v6ibRtPqamXLuS0Bjkq4I4//ImTNy5jHhIQJ7Knew5n6M1iUhbzkPArSC4izxvnkHsfqjrH1/FbKnGUAZI3KYknWEuakzQmZQfgHag/0GKvbm4nJwZqD3DDhBqyG/EoHm/wPiJCWGpvKNTnX+OXaW89v5ePyj3vUhCsbK3nn5DuUO8u5ceKNIZFYna1Oj0kVoF230+JqkaQaAuTxX0SkysZKPi7/GOg5uaDz893VuzladzQosfWWEDXwalUWZSHGEhOAaMRAJKmKiLS7arfHYVsKxc7K0NicYm76XI+jIAwM5qTNkVpqiJCkKiLSuYZzHhOVRnOu4VwAI3IvPS6dyzIu6/ecQhFtiWZF9ooARyXckbc2EZG8qdWFUs3vxok3MipqFNsqttFutncdH2Mbw62TbiU1NjWI0YnuQuenRogAyk/O55TzlNvzBgbTU6YHMCLPDGVw1birWD5mOScdJ2lztTF61GiyRvW31rsIJkmqIiLNy5jHlvNbaG5v7rdXXSnFosxFQYjMsxhLTEgle9GXtKmKiBRnjeO+/Pu6xrt2H1YVZUTx1byvytRPMSTKm10dg+XS5n92u91OYmJisMMRI1Crq5XiC8WctJ9Eo8mJz2Fu+lyfTS4QI4fD4SApKQkgSWvtcFdOkqoQQnjB26Qqj/9CCOFDklSFEMKHJKkKIYQPSVIVQggfkqQqhBA+JElVCCF8SJKqEEL4kExTFSJMnGs4x7mGc1iUhSlJU0iMlrHboUiSqhAhrqaphrdPvt1jKUKFYnbabG6aeBPRluggRid6k8d/IUKYo9XBy0de5nzD+R7HNZqi2iJeP/Y6oTwrMhJJUhUihG2v2E5Te1O/K2lpNCcdJyl1lgYhMuGOJFUhQtj+mv0eN/wzMDhQcyCAEYmBSFIVIoQ1tTd5PG9i0tDWEKBohDckqQoRwgbaSdXAICk6KUDRCG9IUhUihM0fPb/HAtq9mZjMy5gXwIjcM7XJuYZznHKeor6tPtjhBI0MqRIihC3KXMTBmoPUtdT1u/vrnLQ5jLWNDUJkX9Bas7tqN5vPbcbZ5gQ6hnzNSJ3B9eOvJyHac217pJGaqhAhLM4ax4MzHiQ/Jb9HjTXaiGZl9kpunXwrSrmvyQbCxrMbee/Ue10JFTpGJhy5cIQXD78YcbVWqakKEeLio+K5M+9OnK1OKhorsBgWxtnGhcSg/4stF9l0blO/50xMHK0OPjv3GddPuD7AkQWP1FSFCBMJ0QnkJecxOXFySCRUgP3V+z22+Wo0e6v3Yuq+TRcjlSRVIcSQ1bXWeUyqAK1mK82u5gBFFHzy+C+EGLJR1lEDljGUQbQR/Jp1TVMN9lY7o6yjyBqV5be2aEmqQoghm502m20V29yeVyhmpszEagQv1ZTXl/PhqQ8523C261h6bDrXjr+WqclTfX4/efwXQgxZti2baSnT+m0CUCgshoUV2SuCEFmHcmc5fzzyxx4rfAHUNNfwWslrHL5w2Of3lKQqhBiW26fczpz0OV1fdybYxOhE7s+/n9GjRgcrNN4/9T6mNt2un/Be2Xu4tMun95THfyHEsEQZUayZvIbVY1dTUldCm9nG6FGjmZw4GUMFr95W1VTF+cbzHss0tDdwwn7Cp80AklSFED6RFJPEwsyFwQ6ji73F7lW5upY6n95XHv+FECOSNyMTAGxRNp/e1y9JVSk1USn1klKqVCnVpJQ6oZT6V6VU8MdVCCEiQrYtm5SYFI9loo1o8pLyfHpff9VUp1269jeAmcC3gW8C/+6n+wkhRA9KKa7NudZjmVXjVvl8dpoK1P42SqnvAo9qrScP4jWJgN1ut5OYKDtHCiEGr6i2iPdPvU9TexMKhUYTZUSxauwqlmQt8XoSgMPhICkpCSBJa+1wVy6QHVVJwAVPBZRSMUBMt0ORtWaYEINU0ViBvcXOqKhRjLWNDWpve6ianTab6SnTOW4/3vVvlZ+c77f1EwKSVJVSucA/AP97gKI/BH7k/4iECG+nnad5/9T7VDRWdB1Lik7i2vHXMjN1ZhAjC01Ww8q0lGkBudeg3taUUj9TSukBPqb1es1Y4EPgTa317we4xU/pqNF2fowbTHxCRIJyZzmvfP4KlY2VPY7bW+28efxNDtYcDFJkAgZfU/0l8McBypzs/EQplQ1sAAqBRwa6uNa6BWjp9vpBhifEyPfB6Q88zhJ6/9T7zEidEdT59pFsUP/qWutqoNqbspdqqBuAPcADWkfQgopC+El1U3Wfeey9NbuaKakrYUbqjABFJbrzy1vZpYS6EThFRztqRmetU2td4f6VQghPHK1uO527KJRX5YR/+Ov54Bog99LHmV7n5JleiCHyZvaPRvt8lpDwnl/GX2it/6i1Vv19+ON+QkSKzLhMMmIzPJaJNqLJT84PUESiNxnUJkQYUUpx7XjPs4RWj1sdMntYRSJJqkKEmbzkPO7Ku4uEqJ5zY2IsMfzd+L9jUeaiIEUmQJb+EyIsTUuZRl5yHqX2Uupa67BZbeQm5xJlRAU7tIgnSVWIMGVRFnKTc4MdhuhFHv+FEMKHJKkKIYQPSVIVQggfkqQqhBA+JElVCCF8SJKqEEL4UFgMqXI4ZHEIIURweZuHArZH1VBcWu2q94IsQggRTOO01mfdnQz1pKqAbMA5jMsk0JGYxw3zOqFEvqfQN9K+H5DvqbP8Oe0hcYb04/+lwN2+I3ij2+4BTk87IIYT+Z5C30j7fkC+p0sGLCMdVUII4UOSVIUQwociIam2AP9Ktw0FRwD5nkLfSPt+QL4nr4R0R5UQQoSbSKipCiFEwEhSFUIIH5KkKoQQPiRJVQghfEiSqhBC+FBEJlWlVIxSar9SSiulCoIdz1AppSYqpV5SSpUqpZqUUieUUv+qlAqr/YmVUo8rpcqUUs1KqR1KqcuDHdNQKaV+qJTapZRyKqWqlFJrlVL5wY7Ll5RSP7j0u/NssGMZDqXUWKXU/1NK1V76/SlSSi0Y7nUjMqkCPwfOBTsIH5hGx//hN4CZwLeBbwL/HsygBkMpdSfwKzrGCs4HDgAfKaVGBzWwobsCeB5YDFwDRAHrlFK2oEblI0qphXT8vB0MdizDoZRKAbYCbcDfATOAJ4GLw752pI1TVUr9HR2/xLcDh4B5Wuv9QQ3Kh5RS3wUe1VpPDnYs3lBK7QB2aa2/delrAygHntNa/yyowfmAUioDqAKu0FpvDnY8w6GUigf2Ao8B/xfYr7V+IqhBDZFS6mfAMq31Cl9fO6JqqkqpTOD3wN8DjUEOx1+SgAvBDsIbl5opLgM+6TymtTYvfb0kWHH5WNKlv8Pi/2QAzwPvaa0/GbBk6LsZ2K2UevNSM80+pdTDvrhwxCTVS8sI/hF4QWu9O8jh+IVSKhf4B+B3wY7FS+mABajsdbwSyAp8OL51qdb9LLBVa10c5HCGRSl1Fx3NMz8Mdiw+Mhl4FDgGXAf8FvgPpdT9w71w2CdVpdTPLjWae/qYRkeySQB+GuSQBzSI76n7a8YCHwJvaq1/H5zIRS/PA7OAu4IdyHAopXKAXwP3aK2bgx2PjxjAXq31P2mt92mt/4uOp9hvDvfCIb2eqpd+SUcN1JOTwGo6Hilbuq2hCB2PAK9qrYf9DuVD3n5PACilsoENQCHwiP/C8rkawAVk9jqeCVQEPhzfUUr9J3ATsFJrHe67V1wGjAb2dvvdsQArlVLfAmK01q5gBTdE54HDvY4doaOvZVjCPqlqrauB6oHKKaX+Fx2N652ygY+AO4Ed/oluaLz9nqCrhroB2AM8cKlNMixorVuVUnuAq4C10PXIfBXwn0EMbcguNTM9B6wBrtRalwY5JF/4FJjd69gfgM+Bp8IwoUJHz3/voW5TgVPDvXDYJ1Vvaa1Pd/9aKVV/6dMT4VqTuJRQN9Lxg/C/gYzOmoTWOlxqer8CXlFK7QZ2Ak8ANjp+acPR88DdwC2AUynV2TZs11o3BS+sodNaO4EebcJKqQagNozbip8BCpVS/wT8Bbicjqe8YT/pRUxSHaGuAXIvffR+Y1B9i4cerfUbl4Yd/ZiOzqn9wPVa696dV+Hi0Ut/b+x1/AEGbtIRAaK13qWUWkNHH8s/A6XAE1rrV4d77YgbpyqEEP4U9r3/QggRSiSpCiGED0lSFUIIH5KkKoQQPiRJVQghfEiSqhBC+JAkVSGE8CFJqkII4UOSVIUQwockqQohhA9JUhVCCB/6/wFQAjlHmOCoOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Giving color, size for the plot\n",
    "# For more colormaps, refer \"https://gallantlab.github.io/pycortex/colormaps.html\"\n",
    "plt.rcParams['image.cmap'] = \"Accent_r\"\n",
    "plt.rcParams['figure.dpi'] = \"100\"\n",
    "\n",
    "# Generate a 2-D classification dataset\n",
    "X, y = make_blobs(centers=2, cluster_std=2, random_state=0, n_samples=60, n_features = 2)\n",
    "\n",
    "# plot the figure using plt\n",
    "plt.figure()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "# We will be using scatter plot from the matplotlib\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7KdXS33nRua"
   },
   "source": [
    "## <font color = 'pickle'>**Adding new points**\n",
    "We have added three new points represented as **Stars** in our scatterplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yk1FoUhu43d"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1aX94_JUVtQDm47woCrbTE9EjTVPDYOo2\" width =400 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K12xC97tPoGs"
   },
   "source": [
    "## <font color = 'pickle'>**Calculate Distance**</font>\n",
    "\n",
    "* We can use following disatnce formulae to find nearest neighbours:-\n",
    "   * Euclidian distance\n",
    "   * Manhattan distance\n",
    "* **Euclidian distance** :\n",
    "  If we have  data $(x_{11}, x_{12}),(x_{21},x_{22})$ points  then finding the\n",
    "  distance between those points by using Euclidean distance is done as follows :\n",
    "\n",
    "  **Euclidean distance** = $\\sqrt{(x_{11}, x_{12})^2 + (x_{21},x_{22})^2}$      \n",
    "\n",
    "* **Manhattan distance** :\n",
    "  Just like Euclidian distance we can find the Manhattan distance for the above points\n",
    "as follows :\n",
    "\n",
    "   **Manhattan distance** =  $|x_{11}, x_{12}| + |x_{21},x_{22}|$      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M_0cw-2vK11"
   },
   "source": [
    "### <font color = 'pickle'>**Classifying the new data points** </font>\n",
    "Now we need to classify these new data points.We can predict the classification of these new data points based on the euclidean distance.\n",
    "\n",
    "If we use one nearest neighbour then kNN will predict the label of the new data point  based on the label of closest point in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeVQMEoGwaPh"
   },
   "source": [
    "<img src =\"https://drive.google.com/uc?export=view&id=1256ce01O6b6aTySzgHkX6EOObakdec32\" width =400 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHMayvx00dJU"
   },
   "source": [
    "* From the above figure we can see that the new point has been classified based on  the nearest point. We have also shown which nearest data points are used to classify new data points.\n",
    "\n",
    "* In this case new points were classified as black\n",
    "* Hence, the new points changed it's color (from red to black or green) based on the nearest point color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uetez5u50-iH"
   },
   "source": [
    "#<font color = 'pickle'>**Splitting the dataset**</font>\n",
    "* We need to split the data into a **training set** and a **test set**.\n",
    "* We can consider 75 % of the data as a training set then we use training set to train the model.\n",
    "* The rest of the 25% of the data is considered as a test set which is used to test our model accuracy.\n",
    "\n",
    "If our assumption is correct, and we get a 90% success rate on the test data, we expect about a 90% success rate on any future data, for which we don't have labels.\n",
    "\n",
    "But, **why do we need to split the dataset into train and test sets**?\n",
    "Let's discuss about this as follows :-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdXOCUOMyt7F"
   },
   "source": [
    "## <font color = 'pickle'>**Why to split the dataset**\n",
    "\n",
    "* Let us assume that we want to teach multiplicaion to students. For demonstration we used numbers from 1 to 9.\n",
    "* Now we have to test whether our students understood the multiplication.\n",
    "* If we give the same set of numbers to multiply, there is a possibility that the student might have **memorized the results**. But we want to know whether he/she understood the concept of number multiplication.\n",
    "* Hence we will give them a new set of numbers probably ranging from 11 to 20 and ask them to give results on the new set of numbers.\n",
    "* From this example, we can derive following things :-\n",
    "\n",
    "**Teaching students multiplication** - training the model.\n",
    "\n",
    "**students** - students are considered as our model.\n",
    "\n",
    "**Numbers from 1 to 9** - This is our training data set. We will train our model based on these numbers.\n",
    "\n",
    "**Number from 11 to 20** - This is considered as test data set. By applying our model on test data set we will get to know how well our model works on the new set of datasets. We can conclude that it can perform well on any other datasets as well.\n",
    "\n",
    "*  The train and test data sets also help us to avoid the problems of overfitting which will discuss in detail below.\n",
    "\n",
    "Thus, the above example gives a clear explanation about the importance of splitting the data.\n",
    "Now let's check how to split the data by using scikit learn as follows :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8Ulv5Rp1u9c"
   },
   "source": [
    "## <font color = 'pickle'>**Splitting dataset using scikit-learn**\n",
    "  Scikit learn is one of the essential packages for data science. We can use scikit learn to split the data into two parts i.e train and test data sets.\n",
    "\n",
    "  **Syntax** :\n",
    "\n",
    "\n",
    "```\n",
    " from sklearn.model.selection import train_test_split\n",
    " X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
    "\n",
    "```\n",
    "where X, Y is our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u4oXIZC20bhk"
   },
   "outputs": [],
   "source": [
    "# Split the dataset using scikit-learn\n",
    "# We provide it with the data X, which are our two features, and the labels y.\n",
    "# ramdom_state is used for reproducability. It will make sure that every time we\n",
    "# run this cell we get the exact same train/test split\n",
    "\n",
    "# import train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split X, y in to (X_train, X_test ) and (y_train, y_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1662323982722,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "Mcefi4CA2b21",
    "outputId": "27cc4f97-6575-4951-dbd1-6b4cfbff3aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate kNN for k=1 which is one neighbors classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# applying kNeighborClassifier by taking the number of neighbors as 1\n",
    "my_knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Now we call the fit method\n",
    "# The fit method builds the model and stores any estimated quantities in the model object.\n",
    "# Here its my_knn. In case of KNeighborsClassifier, the fit method helps in remembering\n",
    "# the whole training set.\n",
    "\n",
    "# fit the model\n",
    "my_knn.fit(X_train, y_train)\n",
    "\n",
    "# Let's use the score method\n",
    "# Score method will compute the accuracy for classification problems\n",
    "\n",
    "print(f\"Accuracy: {my_knn.score(X_test, y_test):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChEl9tzwBO9L"
   },
   "source": [
    "# <font color = 'pickle'>**Overfitting and Underfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ezPgS2EIeE"
   },
   "source": [
    "## <font color = 'pickle'>**Overfitting**\n",
    "\n",
    "* Overfitting usually happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data (test data).\n",
    "* This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model.\n",
    "* The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize.\n",
    "* Hence, our training dataset gives good result but when we apply on the test data set it doesn't give us good accuracy compared to training data's accuracy.\n",
    "* We can understand more about overfitting by the following figure :-\n",
    "\n",
    "\n",
    "If we are trying to do a classification model then the appropriate model is given below :\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=141-VRrdVwtqhi40LqVvqvNaieLx898xC\" width =200 >\n",
    "\n",
    "\n",
    "If we train our model in a wrong way, then we may face the problem of overfitting as follows :-\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1wWifbGcjSwVHjaoybtkzH6f1fCORfSN4\" width =200 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoRAsTY2_6x2"
   },
   "source": [
    "## <font color = 'pickle'>**Underfitting**\n",
    "\n",
    "* Underfitting refers to a model that can neither model the training data nor generalize to new data(test data).\n",
    "\n",
    "* Its occurrence simply means that our model or the algorithm does not fit the data well enough.  \n",
    "\n",
    "* The reason for the occurence of underfitting can be due to the less amount of features in the data or when we try to build a linear model with a non-linear data.\n",
    "\n",
    "\n",
    "Following example gives a good example of underfitting of the model as follows :-\n",
    "\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1oZEtiZf5QP7qSR5g6aHyT5s-2xUkoLZR\" width =200 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fhat0qaxrUoF"
   },
   "source": [
    "<font color = 'dodgerblue'>**Summary**\n",
    "\n",
    "* <font color = 'dodgerblue'> If model is too simple , we will observe **underfitting**.\n",
    "* <font color = 'dodgerblue'> If model is too complex, we will observe **overfitting**.\n",
    "* Somewhere in the middle, we can find a **sweet spot**. Which lies between underfitting and overfitting.\n",
    "* The goal is to select the sweet spot, which is challenging to do in practice.\n",
    "* So, for KNeighborsClassifier, what parameters correspond to high/low model complexity?\n",
    "\n",
    " <font color = 'dodgerblue'>  **high n_neighbors = low complexity**\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1api1X6sPpwPRNrfNAZo6G317m994PUSn\" width =500 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gvSPcLWV-lh"
   },
   "source": [
    "#<font color = 'pickle'> **Model complexity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfENUCXT6_u2"
   },
   "source": [
    "##<font color = 'pickle'> **Model Complexity (KNN) Influence of number of neighbors**\n",
    "* The number of neighbors(k) in kNN is a <font color = 'dodgerblue'> **hyperparameter** </font> that we need choose at the time of model building.\n",
    "* We can think of k as a controlling variable for the prediction model.\n",
    "* Samller value of k can lead to overfitting whereas higher values of k can lead to underfitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ows8ZgmoQ9Y5"
   },
   "source": [
    "The kNN classification by considering K = 5 :-\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1-1Ci8e7ZSClo7YixJtJu1PP5U8O5Ng_P\" width =300 >\n",
    "\n",
    "We can draw the following conclusions :-\n",
    "* The new data points are classified based on the 5 nearest data points.\n",
    "* If the 5 datapoint around the new data point are of different colour then it will be classified based on the higher number of same coloured data points.\n",
    "* For example, if there are 3 green data points and 2 black data points then our new data point will be classified as green. Since, we have more  green points(i.e 3) when compared to black points(i.e 2).\n",
    "* Similarly, we have kNN regression, the value for the new data point is calculated based on the average of the values of k nearest neighbors.\n",
    "Where k value is given by the user or we can calculate by using cross validation methods which will discussed below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHR-e9LgSlX7"
   },
   "source": [
    "* Let's plot decision boundary using different number of neighbors(K).\n",
    "\n",
    "> Definition of Decision Boundary from [wikipedia ](https://en.wikipedia.org/wiki/Decision_boundary): \"*In a statistical-classification problem with two classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two sets, one for each class. The classifier will classify all the points on one side of the decision boundary as belonging to one class and all those on the other side as belonging to the other class*.\"\n",
    "\n",
    "\n",
    "We have chosen data with only two features (x1 and x2). Decision boundary will be a function of x1 and x2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h24V4phPxRHQ"
   },
   "source": [
    "<img src =\"https://drive.google.com/uc?export=view&id=1-1o0Cjqz9xCEG5HiQ8izWrYz-6ihjL_Z\" width = 700 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFZCffik_VVz"
   },
   "source": [
    "From the above figure we can derive how classification changes based on the different number of neighbors.\n",
    "* A scattered plot is used to plot the x1 and x2 values .\n",
    "* black and green circles represents two classses of points in training dataset.\n",
    "* the background represents a class a new datapoint  (e.g. point in test data set) would be assigned to for each value of x1 and x2.\n",
    "* If we choose **k = 1**, we will pick up a **lot of noise** in the model.\n",
    "* But if we increase the value of of k (k = 5, 10, 40), we will notice that we achieve smooth separation.\n",
    "* This cleaner cut off is achieved at the cost of miss - labeling some data points such as when the  **k = 50**.\n",
    "* When **n_neighbors** = 60 i.e it reaches to the total number of samples then it will remove the decsion boundary and  will display the backgorund color based on the class which has more points in training dataset. In this example the black points has more observations and hence background color is black. In other words when n_neighbors = number of samples, then we use a very simple model, which always predict a new point based on the class which has more observations in the training dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNswYrfQAQhY"
   },
   "source": [
    "Now let's check in detail behavior of our data for different values of k mentioned above: 1, 5, 10, 30, 40, 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sOF_BiyIHp2"
   },
   "outputs": [],
   "source": [
    "# Let's classify the data again based on the different k values\n",
    "# Consider different k values ranging from 1 to 30 with a difference of 2\n",
    "neighbors = range(1, 31, 2)\n",
    "\n",
    "# Create the empty lists\n",
    "training_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Split teh data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)\n",
    "\n",
    "for n_neighbors in neighbors:\n",
    "    # fit the model\n",
    "    nn = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X_train, y_train)\n",
    "    # get the accuracy by using score method for train and test data\n",
    "    training_scores.append(# code here)\n",
    "    test_scores.append(# code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1662324660861,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "HxDh6VlzL4pJ",
    "outputId": "41fbf38d-f320-4aa7-ae86-eb750576238e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_scores: [1.0, 0.8222222222222222, 0.8, 0.7777777777777778, 0.6888888888888889, 0.8, 0.6888888888888889, 0.6666666666666666, 0.6888888888888889, 0.7111111111111111, 0.7111111111111111, 0.6888888888888889, 0.7111111111111111, 0.7111111111111111, 0.7111111111111111]\n",
      "test_scores: [0.6666666666666666, 0.8, 0.7333333333333333, 0.8, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.6666666666666666, 0.8, 0.8, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.6666666666666666, 0.7333333333333333]\n"
     ]
    }
   ],
   "source": [
    "print(f\"training_scores: {training_scores}\\ntest_scores: {test_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U65vLjEXKiRo"
   },
   "source": [
    "Now let's plot the above training_scores and test_scores as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1662324667430,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "wogyaKzvJp3k",
    "outputId": "48205f73-bdac-40cc-9430-f0735e250a57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0be9e2f410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's plot the data as follows\n",
    "# Here we will check the accuracy for different neighbors ranging from 1 to 30\n",
    "plt.figure()\n",
    "# plot the number of neighbors and training_scores\n",
    "plt.plot(neighbors, training_scores, label=\"training scores\")\n",
    "# plot the number of neighbors and test_scores\n",
    "plt.plot(neighbors, test_scores, label=\"test scores\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRUmUsOFK6Mm"
   },
   "source": [
    "From the above graph we can make following assumptions :\n",
    "1. if k = 1, then our accuracy is 1(perfect) but the test score is 50% (not so good).\n",
    "2. If we increase the k values, the training scores goes down.\n",
    "4. We will decide the k values based on the test dataset accuracy. Since, we want to know the accuracy of our model based on the new data. Hence, we give preference to testdata set accuracy rate.\n",
    "\n",
    "3. Since, it is difficult to interpret the best k values by using above graph. We have several ways to find the best k value. <font color = 'dodgerblue'> **The process of finding best values for hyperparameters is caled hyperparameter tuning.**</font>\n",
    "4. We can use cross validation techniques, three fold split, Grid SearchCv etc. to find the best k values. We will now discuss these in detail :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIHsUIV9QM0m"
   },
   "source": [
    "# <font color = 'pickle'> **Three fold split**\n",
    "So far we have done the splitting of the data into training and test datasets. However, <font color = 'dodgerblue'> if we select optimized  k value based on test data set, then it could happen that the selected k values gives very good results for the test dataset but may not generalize to unseen data. In other words we will never now whether the optinmized k value is causing the overfitting.</font>\n",
    "\n",
    "* In order to solve this problem of overfitting the test dataset, we can split the data into three folds that is training set, validation set and test set.\n",
    "* We will train the model by using training set.\n",
    "* The Validation set is used for tuning the hyperparameters.\n",
    "* The test set will be used for the final evaluation of the model.\n",
    "\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=13i9nd9Jp_4Dd0cN-mvDQnyvoEQfAbiON\" width =300 >\n",
    "\n",
    "Note : <font color = 'dodgerblue'> **Hyperparameter is a parameter that cannnot be estimated by fitting the model on training data.**</font> The value of hyerparamter is used to control the learning process e.g. k in the kNN is the hyperparameter. The process of finding the best vaue of hyperparameter using the strategies like cross-validation, gridsearch is called hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1662325042152,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "ld17bh9CTKuS",
    "outputId": "a3a05cee-b7c9-48c4-a602-9ca841b795d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation score: 0.75\n",
      "best_value_of_k: 1\n",
      "test-set score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Three fold split\n",
    "# Using train_test_split to split the data into train, val and test\n",
    "# first split the data into trainval and test datasets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y)\n",
    "# then split trainval into train and val datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval)\n",
    "\n",
    "val_scores = []\n",
    "# Taking k values ranging from 1 to 15 with a step of 2\n",
    "neighbors = np.arange(1, 16, 2)\n",
    "for i in neighbors:\n",
    "    # following same steps for traning the data with kNeighborsClassifier model\n",
    "    nn = KNeighborsClassifier(n_neighbors=i)\n",
    "    nn.fit(X_train, y_train)\n",
    "\n",
    "    # Adding the validation scores to the val_scores\n",
    "    val_scores.append(nn.score(X_val, y_val))\n",
    "\n",
    "# let's consider the highest score for validation data across different k values\n",
    "# the val score for each k was saved in val_score list. The max value will\n",
    "# give us the best validation score\n",
    "print(f\"best validation score: {np.max(val_scores):.3}\")\n",
    "\n",
    "# the index coresponding to best value will give us the best value of k\n",
    "# using the index we will select the corresponding values from neighbours list\n",
    "best_value_of_k = neighbors[# code here]\n",
    "print(\"best_value_of_k:\", best_value_of_k)\n",
    "\n",
    "# fit the model using best k on combined train/validation data\n",
    "knn = KNeighborsClassifier(# code here)\n",
    "knn.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(f\"test-set score: {knn.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hARdAhlcaGyW"
   },
   "source": [
    "In the three fold split we might be using the 70 % to 80% of the data. Our results mostly depends on how we split the data. In to order make it more robust we will be using cross validation as follows :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdqMqQLNBXFX"
   },
   "source": [
    "#<font color = 'pickle'> **Cross-Validation (CV)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iQdrgBHBti3"
   },
   "source": [
    "* In cross-validation, we split our training data into multiple folds, usually 5 or 10\n",
    "* Then we build multiple models based on these folds. Following image gives a clear idea about the concept :\n",
    "\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1LQ_9W5Xeqnj4LNuM5mPmZV3M-nYiy8Hv\" width =700 >\n",
    "\n",
    "*  In the split 1, We start by using fold1  as the validation data, and the remaining ones as the training data. You build your model on the training data, and evaluate it on the test fold. In each split, a different fold is used as validation data.\n",
    "*  For each of the splits of the data, we get a model evaluation and a score. In the end, we can aggregate the scores, for example by taking the mean.\n",
    "* This usually takes longer time but gives better results.\n",
    "\n",
    "* We can use **cross_val_score** from scikit learn to perform cross validation on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD3a5B_QQ-Zr"
   },
   "source": [
    "## <font color = 'pickle'> **Cross-Validation Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhVbmr264X8S"
   },
   "outputs": [],
   "source": [
    "# First split the data into train and test\n",
    "x_train_dummy = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y_train_dummy = np.array([0, 0 ,0 ,0 ,0 ,0 ,0 ,1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1662325191685,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "N3jIrJK44X8U",
    "outputId": "d7f68bf2-dd48-48b8-beef-a6e6fac9f21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train splits\n",
      "Train fold for split 1: [0 1 3 5 6 7] Valid fold for split 1 : [2 4 8 9]\n",
      "Train fold for split 2: [0 2 3 4 5 8 9] Valid fold for split 2 : [1 6 7]\n",
      "Train fold for split 3: [1 2 4 6 7 8 9] Valid fold for split 3 : [0 3 5]\n",
      "\n",
      "y_train splits\n",
      "Train fold for split 1 : [0 0 0 0 0 1] Valid fold for split 1: [0 0 1 1]\n",
      "Train fold for split 2 : [0 0 0 0 0 1 1] Valid fold for split 2: [0 0 1]\n",
      "Train fold for split 3 : [0 0 0 0 1 1 1] Valid fold for split 3: [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfolds = KFold(n_splits = 3, random_state=0, shuffle = True)\n",
    "print(f'X_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(kfolds.split(x_train_dummy)):\n",
    "  print(f'Train fold for split {i+1}: {x_train_dummy[train_fold]} Valid fold for split {i+1} : {x_train_dummy[valid_fold]}')\n",
    "\n",
    "\n",
    "print(f'\\ny_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(kfolds.split(y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1} : {y_train_dummy[train_fold]} Valid fold for split {i+1}: {y_train_dummy[valid_fold]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlAGumZmQaEQ"
   },
   "source": [
    "## <font color = 'pickle'> **Finding the best value of k (hyperparameter) using CV**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1662325483565,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "0x8uqJ1IV3Dl",
    "outputId": "02c1fa4a-bc34-447b-8c5c-cd712db70acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross-validation score: 0.733\n",
      "best_value_of_k: 1\n",
      "test-set score: 0.600\n"
     ]
    }
   ],
   "source": [
    "# Use cross_val_score from scikit learn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# First split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# create empty list to store cross validation scores\n",
    "cross_val_scores = []\n",
    "kfolds = # code here\n",
    "\n",
    "# Taking k values ranging from 1 to 15 with a step of 2\n",
    "neighbors = np.arange(1, 16, 2)\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    # Let's take the cross validation splits as 5\n",
    "    # For each split we get accuracy score i.e we have 5 accuracy values\n",
    "    scores = # code here\n",
    "\n",
    "    # scores will give us five values corrsponding to five validation splits\n",
    "    # We will take mean of these five values and append the mean value to cross_val_score list\n",
    "    cross_val_scores.append(np.mean(scores))\n",
    "\n",
    "# get the  the accuracy i.e highest score by using max() function\n",
    "print(f\"best cross-validation score: {# code here}\")\n",
    "\n",
    "# get the value of number oif neighbors that gives  maximum cross validation score\n",
    "best_n_neighbors = neighbors[# code here]\n",
    "print(f\"best_value_of_k: {best_n_neighbors}\")\n",
    "\n",
    "# Retrain the model with the best_value_of_k\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = best_n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# evaluating the model by using the test set\n",
    "print(f\"test-set score: {knn.score(X_test, y_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d93mVinV1nS6"
   },
   "source": [
    "<font color = 'dodgerblue'> **QUESTION: How many total models we estimated in the above code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdCaoR0ON9VA"
   },
   "source": [
    "<img src =\"https://drive.google.com/uc?export=view&id=1iK80BvXepRL1xHwJWqQa14BiNhJMVH9S\" width =600 >\n",
    "\n",
    "* In the above figure we are splitting the dataset in to training and test set.\n",
    "* We used cross-validation to find the best parameters.\n",
    "* We use the best parameters and the training set to build a model with the best parameters, and finally evaluate it on the test set.\n",
    "* GridSearch CV, does all the steps (implemented using for loop in the code above). Let's discuss more about this .\n",
    "\n",
    "Figure inspired from https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZ4n4jHAkqHU"
   },
   "source": [
    "## <font color = 'pickle'> **Grid search CV**\n",
    "* GridSearchCV is a class, and it behaves just like any other model in scikit-learn, with a fit, predict and score method.\n",
    "* After specifying the KNeighborsClassifier, we can use grid search method by specifying the parameters we want to search, and the cross-validation strategy.\n",
    "* Then grid search will handle  the cross-validation and parameter selection, and retrains a model with the best parameter.\n",
    "\n",
    "\n",
    "\n",
    "**Syntax** :\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "GridSearchCV(estimator, param_grid, scoring=None, refit=True, cv=None, return_train_score = False)\n",
    "(or)\n",
    "sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, refit=True, cv=None return_train_score=False)\n",
    "```\n",
    "where ,\n",
    "\n",
    "**param_grid** = It is a  Dictionary with parameters names (str) as keys and lists of parameter settings to try as values.\n",
    "\n",
    "**cv** =  cross validation generator by default it is considered as 5.\n",
    "\n",
    "**return_train_score** = By default the return_train_score is considered as  **False**, Our cross validation will not include scortes from training fold.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1662325648017,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "ad1OZQvskbnL",
    "outputId": "1d66bcc3-85e7-42ec-9432-fa54dd161993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.711111111111111\n",
      "best parameters: {'n_neighbors': 1}\n",
      "train-set score: 1.000\n",
      "test-set score: 0.467\n"
     ]
    }
   ],
   "source": [
    "# We will now implement above code using GridSearchCV\n",
    "# performing kNN classification and using GridSearchCV for predciting best parameter and retraining\n",
    "# the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# split the data into train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# speciy the param_grid values\n",
    "param_grid = # code here\n",
    "\n",
    "kfolds = KFold(n_splits = 5, random_state=0, shuffle = True)\n",
    "\n",
    "# Using GridSearchCV for kNN classification and returning the train_score as True\n",
    "grid = # code here\n",
    "\n",
    "# Now fit the  GridSearchCV on the X_train, y_train by using fit() method\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# grid.best_score_ gives the best vaklue for the mean of cross validation score\n",
    "# grid.best_params_ generates the best parameter i.e n_neighbor\n",
    "# grid.score(data) gives the score on the data after fitting the model on\n",
    "# complete training data using the best hyper parameters\n",
    "\n",
    "print(f\"best mean cross-validation score: {grid.best_score_}\")\n",
    "print(f\"best parameters: {grid.best_params_}\")\n",
    "\n",
    "# We can check the accuracy score of training dataset and test dataset.\n",
    "print(f\"train-set score: {grid.score(X_train, y_train):.3f}\")\n",
    "print(f\"test-set score: {grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1662325667574,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "GIf2XKIPain7",
    "outputId": "d634f8f9-585b-45a4-f87a-48252cab9bac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3198db04-7ef3-413e-aa0a-74bf6f785795\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.00078</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.688889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.180534</td>\n",
       "      <td>0.150718</td>\n",
       "      <td>0.070273</td>\n",
       "      <td>0.054433</td>\n",
       "      <td>0.121716</td>\n",
       "      <td>0.150718</td>\n",
       "      <td>0.150718</td>\n",
       "      <td>0.129577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06431</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>0.030429</td>\n",
       "      <td>0.028328</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>0.03768</td>\n",
       "      <td>0.027217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3198db04-7ef3-413e-aa0a-74bf6f785795')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3198db04-7ef3-413e-aa0a-74bf6f785795 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3198db04-7ef3-413e-aa0a-74bf6f785795');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                     0                   1  \\\n",
       "mean_fit_time                  0.00078             0.00065   \n",
       "std_fit_time                  0.000253            0.000022   \n",
       "mean_score_time               0.001233            0.001169   \n",
       "std_score_time                 0.00027            0.000055   \n",
       "param_n_neighbors                    1                   3   \n",
       "params              {'n_neighbors': 1}  {'n_neighbors': 3}   \n",
       "split0_test_score             0.444444            0.333333   \n",
       "split1_test_score             0.888889            0.666667   \n",
       "split2_test_score             0.555556            0.777778   \n",
       "split3_test_score             0.777778            0.666667   \n",
       "split4_test_score             0.888889            0.666667   \n",
       "mean_test_score               0.711111            0.622222   \n",
       "std_test_score                0.180534            0.150718   \n",
       "rank_test_score                      1                   8   \n",
       "split0_train_score                 1.0            0.916667   \n",
       "split1_train_score                 1.0            0.805556   \n",
       "split2_train_score                 1.0            0.777778   \n",
       "split3_train_score                 1.0            0.833333   \n",
       "split4_train_score                 1.0            0.722222   \n",
       "mean_train_score                   1.0            0.811111   \n",
       "std_train_score                    0.0             0.06431   \n",
       "\n",
       "                                     2                   3  \\\n",
       "mean_fit_time                 0.000633            0.000816   \n",
       "std_fit_time                  0.000016            0.000333   \n",
       "mean_score_time               0.001115            0.001312   \n",
       "std_score_time                0.000015            0.000253   \n",
       "param_n_neighbors                    5                   7   \n",
       "params              {'n_neighbors': 5}  {'n_neighbors': 7}   \n",
       "split0_test_score             0.555556            0.555556   \n",
       "split1_test_score             0.777778            0.666667   \n",
       "split2_test_score             0.666667            0.666667   \n",
       "split3_test_score             0.666667            0.555556   \n",
       "split4_test_score             0.666667            0.666667   \n",
       "mean_test_score               0.666667            0.622222   \n",
       "std_test_score                0.070273            0.054433   \n",
       "rank_test_score                      5                   7   \n",
       "split0_train_score            0.861111                0.75   \n",
       "split1_train_score            0.722222            0.777778   \n",
       "split2_train_score            0.777778                0.75   \n",
       "split3_train_score                0.75            0.777778   \n",
       "split4_train_score                0.75            0.694444   \n",
       "mean_train_score              0.772222                0.75   \n",
       "std_train_score               0.047791            0.030429   \n",
       "\n",
       "                                     4                    5  \\\n",
       "mean_fit_time                 0.000675             0.000647   \n",
       "std_fit_time                  0.000123             0.000023   \n",
       "mean_score_time               0.001206             0.001119   \n",
       "std_score_time                0.000236              0.00002   \n",
       "param_n_neighbors                    9                   11   \n",
       "params              {'n_neighbors': 9}  {'n_neighbors': 11}   \n",
       "split0_test_score             0.555556             0.555556   \n",
       "split1_test_score             0.666667             0.888889   \n",
       "split2_test_score             0.888889             0.888889   \n",
       "split3_test_score             0.666667             0.666667   \n",
       "split4_test_score             0.555556             0.555556   \n",
       "mean_test_score               0.666667             0.711111   \n",
       "std_test_score                0.121716             0.150718   \n",
       "rank_test_score                      5                    1   \n",
       "split0_train_score            0.777778                 0.75   \n",
       "split1_train_score                0.75             0.694444   \n",
       "split2_train_score            0.694444             0.722222   \n",
       "split3_train_score            0.722222             0.722222   \n",
       "split4_train_score            0.722222             0.722222   \n",
       "mean_train_score              0.733333             0.722222   \n",
       "std_train_score               0.028328             0.017568   \n",
       "\n",
       "                                      6                    7  \n",
       "mean_fit_time                  0.000649             0.000597  \n",
       "std_fit_time                   0.000018             0.000019  \n",
       "mean_score_time                0.001223              0.00111  \n",
       "std_score_time                 0.000101             0.000018  \n",
       "param_n_neighbors                    13                   15  \n",
       "params              {'n_neighbors': 13}  {'n_neighbors': 15}  \n",
       "split0_test_score              0.555556             0.555556  \n",
       "split1_test_score              0.888889             0.888889  \n",
       "split2_test_score              0.888889             0.777778  \n",
       "split3_test_score              0.666667             0.666667  \n",
       "split4_test_score              0.555556             0.555556  \n",
       "mean_test_score                0.711111             0.688889  \n",
       "std_test_score                 0.150718             0.129577  \n",
       "rank_test_score                       1                    4  \n",
       "split0_train_score             0.833333             0.805556  \n",
       "split1_train_score                 0.75             0.722222  \n",
       "split2_train_score                 0.75                 0.75  \n",
       "split3_train_score                 0.75                 0.75  \n",
       "split4_train_score             0.722222                 0.75  \n",
       "mean_train_score               0.761111             0.755556  \n",
       "std_train_score                 0.03768             0.027217  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import results from each split into a Pandas Dataframe\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGStGKmO2H5r"
   },
   "source": [
    "<font color = 'dodgerblue'> **QUESTION1: How many total models we estimated in the above code**\n",
    "<br><br>\n",
    "**QUESTION2: Which model we will finally use to make predictions on Test Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvRbLX_irKmC"
   },
   "source": [
    "## <font color = 'pickle'> **Different types of cross validation iterators**</font>\n",
    "\n",
    "\n",
    "1. Cross-validation iterators for i.i.d. data\n",
    "2.  Cross-validation iterators with stratification based on class labels\n",
    "4. Cross-validation iterators for grouped data\n",
    "5. Cross validation of time series data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k57E3TsWt2WG"
   },
   "source": [
    "## **Cross-validation iterators for i.i.d. data**\n",
    "From wikipedia (https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n",
    "<br>\n",
    "*'In machine learning theory, i.i.d. assumption is often made for training datasets to imply that all samples stem from the same generative process and that the generative process is assumed to have no memory of past generated samples.'*\n",
    "<br>\n",
    "\n",
    "Based on this assumption we can have different types of cross validation iters as follows :\n",
    "\n",
    "1. k-fold\n",
    "2. Repeated k-fold\n",
    "3. Leave One Out (LOO)\n",
    "4. Shuffle and split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpdT5ao1w-H4"
   },
   "source": [
    "###<font color = 'pickle'> **k-fold**\n",
    "* KFold divides all the samples in  groups of sub-samples, called folds.\n",
    "* The prediction function is learned using $1-k$ folds, and the fold left out is used for validation.\n",
    "\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1-6NNMoNLgcb8468KdmEsWStFaMRmO2pR\" width =500 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c14rd3ttdPa"
   },
   "outputs": [],
   "source": [
    "# Generate Dummy Data\n",
    "x_train_dummy = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y_train_dummy = np.array([0, 0 ,0 ,0 ,0 ,0 ,0 ,1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1662326069653,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "yRQdsaU-xCj9",
    "outputId": "a3f4b65b-b0df-411d-d612-855bb50b5566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train splits\n",
      "Train fold for split 1: [0 1 3 5 6 7] Valid fold for split 1 : [2 4 8 9]\n",
      "Train fold for split 2: [0 2 3 4 5 8 9] Valid fold for split 2 : [1 6 7]\n",
      "Train fold for split 3: [1 2 4 6 7 8 9] Valid fold for split 3 : [0 3 5]\n",
      "\n",
      "y_train splits\n",
      "Train fold for split 1 : [0 0 0 0 0 1] Valid fold for split 1: [0 0 1 1]\n",
      "Train fold for split 2 : [0 0 0 0 0 1 1] Valid fold for split 2: [0 0 1]\n",
      "Train fold for split 3 : [0 0 0 0 1 1 1] Valid fold for split 3: [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "folds = KFold(n_splits = 3, random_state=0, shuffle = True)\n",
    "\n",
    "print(f'X_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split(x_train_dummy)):\n",
    "  print(f'Train fold for split {i+1}: {x_train_dummy[train_fold]} Valid fold for split {i+1} : {x_train_dummy[valid_fold]}')\n",
    "\n",
    "\n",
    "print(f'\\ny_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split( y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1} : {y_train_dummy[train_fold]} Valid fold for split {i+1}: {y_train_dummy[valid_fold]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPKuWYaex_q0"
   },
   "source": [
    "###<font color = 'pickle'> **Leave one out**\n",
    "* LeaveOneOut (or LOO) is a simple cross-validation.\n",
    "* Each learning set is created by taking all the samples except one.\n",
    "* The left out sample is the Validation set.\n",
    "* Thus, for  samples, we have  different training sets and  different validation set.\n",
    "* The main advantage of  this cross-validation procedure is that it does not waste much data as only one sample is removed from the training set.\n",
    "\n",
    "<font color = 'dodgerblue'> **Useful for small datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1662326159281,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "BR2WAxKe2BNg",
    "outputId": "f1976aa0-2577-4d41-a134-88f1b60ed9c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train splits\n",
      "Train fold for split 1: [1 2 3 4 5 6 7 8 9] Valid fold for split 1 : [0]\n",
      "Train fold for split 2: [0 2 3 4 5 6 7 8 9] Valid fold for split 2 : [1]\n",
      "Train fold for split 3: [0 1 3 4 5 6 7 8 9] Valid fold for split 3 : [2]\n",
      "Train fold for split 4: [0 1 2 4 5 6 7 8 9] Valid fold for split 4 : [3]\n",
      "Train fold for split 5: [0 1 2 3 5 6 7 8 9] Valid fold for split 5 : [4]\n",
      "Train fold for split 6: [0 1 2 3 4 6 7 8 9] Valid fold for split 6 : [5]\n",
      "Train fold for split 7: [0 1 2 3 4 5 7 8 9] Valid fold for split 7 : [6]\n",
      "Train fold for split 8: [0 1 2 3 4 5 6 8 9] Valid fold for split 8 : [7]\n",
      "Train fold for split 9: [0 1 2 3 4 5 6 7 9] Valid fold for split 9 : [8]\n",
      "Train fold for split 10: [0 1 2 3 4 5 6 7 8] Valid fold for split 10 : [9]\n",
      "\n",
      "y_train splits\n",
      "Train fold for split 1 : [0 0 0 0 0 0 1 1 1] Valid fold for split 1: [0]\n",
      "Train fold for split 2 : [0 0 0 0 0 0 1 1 1] Valid fold for split 2: [0]\n",
      "Train fold for split 3 : [0 0 0 0 0 0 1 1 1] Valid fold for split 3: [0]\n",
      "Train fold for split 4 : [0 0 0 0 0 0 1 1 1] Valid fold for split 4: [0]\n",
      "Train fold for split 5 : [0 0 0 0 0 0 1 1 1] Valid fold for split 5: [0]\n",
      "Train fold for split 6 : [0 0 0 0 0 0 1 1 1] Valid fold for split 6: [0]\n",
      "Train fold for split 7 : [0 0 0 0 0 0 1 1 1] Valid fold for split 7: [0]\n",
      "Train fold for split 8 : [0 0 0 0 0 0 0 1 1] Valid fold for split 8: [1]\n",
      "Train fold for split 9 : [0 0 0 0 0 0 0 1 1] Valid fold for split 9: [1]\n",
      "Train fold for split 10 : [0 0 0 0 0 0 0 1 1] Valid fold for split 10: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "folds = LeaveOneOut()\n",
    "\n",
    "print(f'X_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split(x_train_dummy)):\n",
    "  print(f'Train fold for split {i+1}: {x_train_dummy[train_fold]} Valid fold for split {i+1} : {x_train_dummy[valid_fold]}')\n",
    "\n",
    "\n",
    "print(f'\\ny_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split( y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1} : {y_train_dummy[train_fold]} Valid fold for split {i+1}: {y_train_dummy[valid_fold]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yVke7hhunmf"
   },
   "source": [
    "###<font color = 'pickle'>  **Shuffle and split**\n",
    "* The ShuffleSplit iterator will generate a user defined number of independent train / validation dataset splits.\n",
    "\n",
    "* User will specify the parameters test_size (coresponds to validation in our discussion)  and train size and. For each split data will be divided into train and validation folds.\n",
    "\n",
    "* Thus we can run many iterations with reasonably large valdation fold. For example in kfold cross validation if we run 5 splits (five iterations) then the size of validation set is only 20%. With shuffle split we can specify the test_size to be any value (e.g. 40%) and then run as many iterations as we want. For each iteration 40% of data will be randomly sampled and assigned as validation fold.\n",
    "\n",
    "* Since we are taking random samples, it is possibe that (unlike k-fold) some observations never appear in any validation fold across splits.\n",
    "\n",
    "* <font color = 'dodgerblue'> **This is also useful if we want to take a random samle from a very large training dataset.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1662326289454,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "OImUQ3XD6dl3",
    "outputId": "1b21bb64-c547-43d8-bde0-5dd57ea61f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train splits\n",
      "Train fold for split 1: [1 6 7 3 0] Valid fold for split 1 : [2 8 4 9]\n",
      "Train fold for split 2: [9 8 0 6 7] Valid fold for split 2 : [3 5 1 2]\n",
      "Train fold for split 3: [5 1 0 6 9] Valid fold for split 3 : [2 3 8 4]\n",
      "Train fold for split 4: [7 5 8 0 3] Valid fold for split 4 : [6 1 9 2]\n",
      "Train fold for split 5: [1 0 6 8 9] Valid fold for split 5 : [5 2 7 4]\n",
      "\n",
      "y_train splits\n",
      "Train fold for split 1 : [0 0 1 0 0] Valid fold for split 1: [0 1 0 1]\n",
      "Train fold for split 2 : [1 1 0 0 1] Valid fold for split 2: [0 0 0 0]\n",
      "Train fold for split 3 : [0 0 0 0 1] Valid fold for split 3: [0 0 1 0]\n",
      "Train fold for split 4 : [1 0 1 0 0] Valid fold for split 4: [0 0 1 0]\n",
      "Train fold for split 5 : [0 0 0 1 1] Valid fold for split 5: [0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we can speciy train_size and test_size as percantages or integer values\n",
    "folds = ShuffleSplit(n_splits=5, random_state =0, test_size= 0.4, train_size = 0.5)\n",
    "\n",
    "print(f'X_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split(x_train_dummy)):\n",
    "  print(f'Train fold for split {i+1}: {x_train_dummy[train_fold]} Valid fold for split {i+1} : {x_train_dummy[valid_fold]}')\n",
    "\n",
    "\n",
    "print(f'\\ny_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split( y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1} : {y_train_dummy[train_fold]} Valid fold for split {i+1}: {y_train_dummy[valid_fold]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h94R755GusTv"
   },
   "source": [
    "##<font color = 'pickle'> **Cross-validation iterators with stratification based on class labels**\n",
    "* Some of the classification problems can exhibit a large imbalance in the distribution of the target classes.\n",
    "* For example there could be  more negative samples than positive samples.\n",
    "* In such cases it is recommended to use stratified sampling as implemented below :\n",
    "\n",
    "1. Stratified k- fold\n",
    "2. Stratified shuffle split\n",
    "\n",
    "* Hence, it ensures that relative class frequencies is approximately preserved in each train and validation fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUEwNSutzdae"
   },
   "source": [
    "####<font color = 'pickle'>  **Stratified k- fold**\n",
    "* StratifiedKFold is a similar to the k-fold which returns stratified folds.\n",
    "* Each set contains approximately the same percentage of samples of each target class as the complete set.\n",
    "\n",
    "<img src =\"https://drive.google.com/uc?export=view&id=1-7CWGJlnFSpb2VT7mRBwZWtNOSY4w3L2\" width =500 >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1662326344754,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "0aXH1H1jKY3C",
    "outputId": "942002f0-012c-498a-b028-bcedb961dcbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train splits\n",
      "Train fold for split 1: [0 3 5 6 7 9] Valid fold for split 1 : [1 2 4 8]\n",
      "Train fold for split 2: [0 1 2 4 5 7 8] Valid fold for split 2 : [3 6 9]\n",
      "Train fold for split 3: [1 2 3 4 6 8 9] Valid fold for split 3 : [0 5 7]\n",
      "\n",
      "y_train splits\n",
      "Train fold for split 1 : [0 0 0 0 1 1] Valid fold for split 1: [0 0 0 1]\n",
      "Train fold for split 2 : [0 0 0 0 0 1 1] Valid fold for split 2: [0 0 1]\n",
      "Train fold for split 3 : [0 0 0 0 0 1 1] Valid fold for split 3: [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# we can speciy train_size and test_size as percantages or integer values\n",
    "folds = StratifiedKFold(n_splits=3, random_state =0, shuffle = True, )\n",
    "\n",
    "print(f'X_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split(x_train_dummy, y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1}: {x_train_dummy[train_fold]} Valid fold for split {i+1} : {x_train_dummy[valid_fold]}')\n",
    "\n",
    "\n",
    "print(f'\\ny_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split( x_train_dummy, y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1} : {y_train_dummy[train_fold]} Valid fold for split {i+1}: {y_train_dummy[valid_fold]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MUyrGjR0No3"
   },
   "source": [
    "####<font color = 'pickle'>  **Stratified shuffle split**\n",
    "\n",
    "StratifiedShuffleSplit is similar to ShuffleSplit, which returns stratified splits, i.e which creates splits by preserving the same percentage for each target class as in the complete set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 175,
     "status": "ok",
     "timestamp": 1662326373184,
     "user": {
      "displayName": "Harpreet SIngh",
      "userId": "15106381096049879330"
     },
     "user_tz": 300
    },
    "id": "qjzmUSA8WNtO",
    "outputId": "adf591af-c3c7-457a-ee92-baae1c553b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train splits\n",
      "Train fold for split 1: [2 1 3 7 6 9] Valid fold for split 1 : [0 8 4 5]\n",
      "Train fold for split 2: [3 8 2 5 4 9] Valid fold for split 2 : [0 6 1 7]\n",
      "Train fold for split 3: [8 4 6 7 2 5] Valid fold for split 3 : [0 9 3 1]\n",
      "Train fold for split 4: [5 0 4 9 1 8] Valid fold for split 4 : [3 7 6 2]\n",
      "Train fold for split 5: [6 7 5 8 3 4] Valid fold for split 5 : [2 1 0 9]\n",
      "\n",
      "y_train splits\n",
      "Train fold for split 1 : [0 0 0 1 0 1] Valid fold for split 1: [0 1 0 0]\n",
      "Train fold for split 2 : [0 1 0 0 0 1] Valid fold for split 2: [0 0 0 1]\n",
      "Train fold for split 3 : [1 0 0 1 0 0] Valid fold for split 3: [0 1 0 0]\n",
      "Train fold for split 4 : [0 0 0 1 0 1] Valid fold for split 4: [0 1 0 0]\n",
      "Train fold for split 5 : [0 1 0 1 0 0] Valid fold for split 5: [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# we can speciy train_size and test_size as percantages or integer values\n",
    "folds = StratifiedShuffleSplit(n_splits=5, random_state =0, test_size = 0.4 )\n",
    "\n",
    "print(f'X_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split(x_train_dummy, y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1}: {x_train_dummy[train_fold]} Valid fold for split {i+1} : {x_train_dummy[valid_fold]}')\n",
    "\n",
    "\n",
    "print(f'\\ny_train splits')\n",
    "for i, (train_fold, valid_fold) in enumerate(folds.split( x_train_dummy, y_train_dummy)):\n",
    "  print(f'Train fold for split {i+1} : {y_train_dummy[train_fold]} Valid fold for split {i+1}: {y_train_dummy[valid_fold]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngUkU-4Cpjl0"
   },
   "source": [
    "We will introduce iterators for Grouped and Time series Data when we use these specific kind of data later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4WoFPqUq8pO"
   },
   "source": [
    "##<font color = 'pickle'>  Defaults in Sklearn\n",
    "\n",
    "<font color = 'dodgerblue'> **GridserachCV and cross_val_score by default use startifed k-fold. However, we can pass any CV iterator in GridsearchCV and cross_val_score.** </font>\n",
    "<br> For example the code below will use stratifiedKfold with five splits.\n",
    "`GridSearchCV(estimator, param_grid, scoring=None, refit=True, cv=5, return_train_score = False) `\n",
    "\n",
    "We can pass any iterator with cv.\n",
    "\n",
    "e.g. We can first specify iterator : <br>\n",
    "`folds = StratifiedShuffleSplit(n_splits=5, random_state =0, test_size = 0.4 )`\n",
    "\n",
    "Then we can specify GridSeachCv as follows: <br>\n",
    "`GridSearchCV(estimator, param_grid, scoring=None, refit=True, cv=folds, return_train_score = False) `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-K4sCeF33fFL"
   },
   "source": [
    "## References:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
